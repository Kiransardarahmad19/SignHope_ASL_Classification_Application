{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing class 'before' with 124 video directories.\n",
      "Processing class 'book' with 125 video directories.\n",
      "Processing class 'call' with 125 video directories.\n",
      "Processing class 'chair' with 125 video directories.\n",
      "Processing class 'computer' with 125 video directories.\n",
      "Processing class 'doctor' with 125 video directories.\n",
      "Processing class 'drink' with 125 video directories.\n",
      "Processing class 'eat' with 125 video directories.\n",
      "Processing class 'family' with 125 video directories.\n",
      "Processing class 'food' with 125 video directories.\n",
      "Processing class 'friend' with 125 video directories.\n",
      "Processing class 'go' with 125 video directories.\n",
      "Processing class 'help' with 125 video directories.\n",
      "Processing class 'home' with 125 video directories.\n",
      "Processing class 'money' with 125 video directories.\n",
      "Processing class 'read' with 125 video directories.\n",
      "Processing class 'sleep' with 125 video directories.\n",
      "Processing class 'work' with 125 video directories.\n",
      "Processing class 'write' with 125 video directories.\n",
      "Loaded 6567 clips with labels.\n",
      "Processing class 'before' with 36 video directories.\n",
      "Processing class 'book' with 36 video directories.\n",
      "Processing class 'call' with 36 video directories.\n",
      "Processing class 'chair' with 36 video directories.\n",
      "Processing class 'computer' with 36 video directories.\n",
      "Processing class 'doctor' with 36 video directories.\n",
      "Processing class 'drink' with 36 video directories.\n",
      "Processing class 'eat' with 36 video directories.\n",
      "Processing class 'family' with 36 video directories.\n",
      "Processing class 'food' with 36 video directories.\n",
      "Processing class 'friend' with 36 video directories.\n",
      "Processing class 'go' with 36 video directories.\n",
      "Processing class 'help' with 36 video directories.\n",
      "Processing class 'home' with 36 video directories.\n",
      "Processing class 'money' with 36 video directories.\n",
      "Processing class 'read' with 36 video directories.\n",
      "Processing class 'sleep' with 36 video directories.\n",
      "Processing class 'work' with 36 video directories.\n",
      "Processing class 'write' with 36 video directories.\n",
      "Loaded 1895 clips with labels.\n",
      "Processing class 'before' with 19 video directories.\n",
      "Processing class 'book' with 19 video directories.\n",
      "Processing class 'call' with 19 video directories.\n",
      "Processing class 'chair' with 19 video directories.\n",
      "Processing class 'computer' with 19 video directories.\n",
      "Processing class 'doctor' with 19 video directories.\n",
      "Processing class 'drink' with 19 video directories.\n",
      "Processing class 'eat' with 19 video directories.\n",
      "Processing class 'family' with 19 video directories.\n",
      "Processing class 'food' with 19 video directories.\n",
      "Processing class 'friend' with 19 video directories.\n",
      "Processing class 'go' with 19 video directories.\n",
      "Processing class 'help' with 19 video directories.\n",
      "Processing class 'home' with 19 video directories.\n",
      "Processing class 'money' with 19 video directories.\n",
      "Processing class 'read' with 19 video directories.\n",
      "Processing class 'sleep' with 19 video directories.\n",
      "Processing class 'work' with 19 video directories.\n",
      "Processing class 'write' with 19 video directories.\n",
      "Loaded 1005 clips with labels.\n",
      "Epoch 1/10\n",
      "820/820 [==============================] - 28797s 35s/step - loss: 2.9754 - accuracy: 0.0601 - val_loss: 2.9406 - val_accuracy: 0.0662 - lr: 0.0010\n",
      "Epoch 2/10\n",
      "820/820 [==============================] - 9231s 11s/step - loss: 2.7223 - accuracy: 0.1713 - val_loss: 1.9006 - val_accuracy: 0.4566 - lr: 0.0010\n",
      "Epoch 3/10\n",
      "820/820 [==============================] - 13250s 16s/step - loss: 1.3830 - accuracy: 0.6029 - val_loss: 0.5011 - val_accuracy: 0.8851 - lr: 0.0010\n",
      "Epoch 4/10\n",
      "820/820 [==============================] - 12307s 15s/step - loss: 0.3919 - accuracy: 0.8873 - val_loss: 0.1840 - val_accuracy: 0.9296 - lr: 0.0010\n",
      "Epoch 5/10\n",
      "820/820 [==============================] - 9116s 11s/step - loss: 0.2009 - accuracy: 0.9361 - val_loss: 0.1413 - val_accuracy: 0.9460 - lr: 0.0010\n",
      "Epoch 6/10\n",
      "820/820 [==============================] - 9046s 11s/step - loss: 0.1470 - accuracy: 0.9415 - val_loss: 0.1769 - val_accuracy: 0.9243 - lr: 0.0010\n",
      "Epoch 7/10\n",
      "820/820 [==============================] - 27523s 34s/step - loss: 0.1322 - accuracy: 0.9364 - val_loss: 0.0938 - val_accuracy: 0.9423 - lr: 0.0010\n",
      "Epoch 8/10\n",
      "820/820 [==============================] - 11366s 14s/step - loss: 0.1088 - accuracy: 0.9476 - val_loss: 0.0974 - val_accuracy: 0.9513 - lr: 0.0010\n",
      "Epoch 9/10\n",
      "820/820 [==============================] - 10151s 12s/step - loss: 0.1250 - accuracy: 0.9398 - val_loss: 0.1042 - val_accuracy: 0.9428 - lr: 0.0010\n",
      "Epoch 10/10\n",
      "820/820 [==============================] - 11745s 14s/step - loss: 0.1419 - accuracy: 0.9363 - val_loss: 0.1186 - val_accuracy: 0.9301 - lr: 0.0010\n",
      "125/125 [==============================] - 192s 2s/step - loss: 0.1007 - accuracy: 0.9390\n",
      "Test Loss: 0.10067329555749893, Test Accuracy: 0.9390000104904175\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABKUAAAGGCAYAAACqvTJ0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC8AklEQVR4nOzdd3gU9drG8e9ueg+BNCD03kKvIqAoICKgdBVR1HMUVMRj4aiAFRvq67HjUWwUQUCPonQEpfcOUhMghRDS++68f2wSCM2AJLNJ7s91zTW/zM7O3hsxmTz7m2cshmEYiIiIiIiIiIiIlCKr2QFERERERERERKTiUVFKRERERERERERKnYpSIiIiIiIiIiJS6lSUEhERERERERGRUqeilIiIiIiIiIiIlDoVpUREREREREREpNSpKCUiIiIiIiIiIqVORSkRERERERERESl1KkqJiIiIiIiIiEipU1FKRMoli8XC5MmTr/h5R48exWKxMH369GueSURERORa0vmOiJR1KkqJSImZPn06FosFi8XC77//fsHjhmEQERGBxWLh1ltvNSHh1Vu5ciUWi4W5c+eaHUVERERMVJ7Pd861cOFCLBYLVatWxW63mx1HRMoJFaVEpMR5enoyY8aMC7b/9ttvHD9+HA8PDxNSiYiIiFw75f1859tvv6VWrVrExMSwfPlys+OISDmhopSIlLhbbrmFOXPmkJeXV2T7jBkzaNOmDWFhYSYlExEREbk2yvP5Tnp6Oj/88APjx4+nVatWfPvtt2ZHuqT09HSzI4jIFVBRSkRK3PDhwzl9+jRLliwp3JaTk8PcuXMZMWLERZ+Tnp7OE088QUREBB4eHjRs2JC33noLwzCK7Jednc3jjz9OcHAwfn5+3HbbbRw/fvyixzxx4gT33XcfoaGheHh40LRpUz7//PNr90Yv4vDhwwwePJigoCC8vb3p2LEjP//88wX7/ec//6Fp06Z4e3tTqVIl2rZtW+TT1tTUVMaNG0etWrXw8PAgJCSEm266iS1btpRofhERESme8ny+M3/+fDIzMxk8eDDDhg1j3rx5ZGVlXbBfVlYWkydPpkGDBnh6ehIeHs7tt9/OoUOHCvex2+383//9H82bN8fT05Pg4GB69+7Npk2bgMv3uzq/h9bkyZOxWCzs2bOHESNGUKlSJa677joAduzYwahRo6hTpw6enp6EhYVx3333cfr06Yt+z0aPHk3VqlXx8PCgdu3aPPTQQ+Tk5HD48GEsFgvvvPPOBc9bs2YNFouFmTNnXum3VETyuZodQETKv1q1atGpUydmzpxJnz59APjll19ITk5m2LBhvPfee0X2NwyD2267jRUrVjB69GhatmzJokWLePLJJzlx4kSRk4L777+fb775hhEjRtC5c2eWL19O3759L8gQFxdHx44dsVgsjB07luDgYH755RdGjx5NSkoK48aNu+bvOy4ujs6dO5ORkcGjjz5K5cqV+fLLL7ntttuYO3cuAwcOBGDatGk8+uijDBo0iMcee4ysrCx27NjB+vXrC09i//nPfzJ37lzGjh1LkyZNOH36NL///jt79+6ldevW1zy7iIiIXJnyfL7z7bff0qNHD8LCwhg2bBjPPPMM//vf/xg8eHDhPjabjVtvvZVly5YxbNgwHnvsMVJTU1myZAm7du2ibt26AIwePZrp06fTp08f7r//fvLy8li9ejXr1q2jbdu2V5Vv8ODB1K9fn1dffbWwoLdkyRIOHz7MvffeS1hYGLt37+bTTz9l9+7drFu3DovFAsDJkydp3749SUlJPPjggzRq1IgTJ04wd+5cMjIyqFOnDl26dOHbb7/l8ccfv+D74ufnR//+/a8qt4gAhohICfniiy8MwNi4caPx/vvvG35+fkZGRoZhGIYxePBgo0ePHoZhGEbNmjWNvn37Fj5vwYIFBmC8/PLLRY43aNAgw2KxGAcPHjQMwzC2bdtmAMbDDz9cZL8RI0YYgDFp0qTCbaNHjzbCw8ONhISEIvsOGzbMCAgIKMx15MgRAzC++OKLy763FStWGIAxZ86cS+4zbtw4AzBWr15duC01NdWoXbu2UatWLcNmsxmGYRj9+/c3mjZtetnXCwgIMMaMGXPZfURERKT0lefzHcMwjLi4OMPV1dWYNm1a4bbOnTsb/fv3L7Lf559/bgDG22+/fcEx7Ha7YRiGsXz5cgMwHn300Uvuc7ls57/fSZMmGYAxfPjwC/YteK/nmjlzpgEYq1atKtw2cuRIw2q1Ghs3brxkpk8++cQAjL179xY+lpOTY1SpUsW45557LnieiBSfLt8TkVIxZMgQMjMz+emnn0hNTeWnn3665FT2hQsX4uLiwqOPPlpk+xNPPIFhGPzyyy+F+wEX7Hf+p4CGYfD999/Tr18/DMMgISGhcOnVqxfJycklchncwoULad++feE0cgBfX18efPBBjh49yp49ewAIDAzk+PHjbNy48ZLHCgwMZP369Zw8efKa5xQREZFrozye78yaNQur1codd9xRuG348OH88ssvnDlzpnDb999/T5UqVXjkkUcuOEbBrKTvv/8ei8XCpEmTLrnP1fjnP/95wTYvL6/CcVZWFgkJCXTs2BGg8Ptgt9tZsGAB/fr1u+gsrYJMQ4YMwdPTs0gvrUWLFpGQkMBdd9111blFRD2lRKSUBAcH07NnT2bMmMG8efOw2WwMGjToovseO3aMqlWr4ufnV2R748aNCx8vWFut1sLp4AUaNmxY5OtTp06RlJTEp59+SnBwcJHl3nvvBSA+Pv6avM/z38f5WS72Pp5++ml8fX1p37499evXZ8yYMfzxxx9FnvPGG2+wa9cuIiIiaN++PZMnT+bw4cPXPLOIiIhcvfJ4vvPNN9/Qvn17Tp8+zcGDBzl48CCtWrUiJyeHOXPmFO536NAhGjZsiKvrpTvEHDp0iKpVqxIUFHTFOS6ndu3aF2xLTEzkscceIzQ0FC8vL4KDgwv3S05OBhzfs5SUFJo1a3bZ4wcGBtKvX78i/T6//fZbqlWrxg033HAN34lIxaOeUiJSakaMGMEDDzxAbGwsffr0ITAwsFRe1263A3DXXXdxzz33XHSfFi1alEqWi2ncuDH79+/np59+4tdff+X777/nww8/ZOLEibzwwguA4xO6rl27Mn/+fBYvXsybb77J66+/zrx58wr7VoiIiIj5ytP5zp9//lk4k7t+/foXPP7tt9/y4IMPXmHSy7vUjCmbzXbJ55w7K6rAkCFDWLNmDU8++SQtW7bE19cXu91O7969C79XV2LkyJHMmTOHNWvW0Lx5c3788UcefvhhrFbN8xD5O1SUEpFSM3DgQP7xj3+wbt06Zs+efcn9atasydKlS0lNTS3y6eG+ffsKHy9Y2+32wk/mCuzfv7/I8QruVGOz2ejZs+e1fEuXVbNmzQuywIXvA8DHx4ehQ4cydOhQcnJyuP3223nllVeYMGECnp6eAISHh/Pwww/z8MMPEx8fT+vWrXnllVdUlBIREXEi5el859tvv8XNzY2vv/4aFxeXIo/9/vvvvPfee0RFRVGjRg3q1q3L+vXryc3Nxc3N7aLHq1u3LosWLSIxMfGSs6UqVaoEQFJSUpHtBTPHiuPMmTMsW7aMF154gYkTJxZu//PPP4vsFxwcjL+/P7t27frLY/bu3Zvg4GC+/fZbOnToQEZGBnfffXexM4nIxamsKyKlxtfXl48++ojJkyfTr1+/S+53yy23YLPZeP/994tsf+edd7BYLIVFmIL1+Xezeffdd4t87eLiwh133MH3339/0ZOOU6dOXc3b+Uu33HILGzZsYO3atYXb0tPT+fTTT6lVqxZNmjQBuODWxO7u7jRp0gTDMMjNzcVmsxVOMy8QEhJC1apVyc7OLpHsIiIicnXK0/nOt99+S9euXRk6dCiDBg0qsjz55JMAzJw5E4A77riDhISEC94PUHhHvDvuuAPDMApngl9sH39/f6pUqcKqVauKPP7hhx8WO3dBAa3gmAXO/55ZrVYGDBjA//73PzZt2nTJTACurq4MHz6c7777junTp9O8eXNTZ9qLlBeaKSUipepS08nP1a9fP3r06MGzzz7L0aNHiYyMZPHixfzwww+MGzeusKdCy5YtGT58OB9++CHJycl07tyZZcuWcfDgwQuO+dprr7FixQo6dOjAAw88QJMmTUhMTGTLli0sXbqUxMTEq3o/33//feEnmue/z2eeeabwttCPPvooQUFBfPnllxw5coTvv/++cLr3zTffTFhYGF26dCE0NJS9e/fy/vvv07dvX/z8/EhKSqJ69eoMGjSIyMhIfH19Wbp0KRs3bmTq1KlXlVtERERKTnk431m/fj0HDx5k7NixF328WrVqtG7dmm+//Zann36akSNH8tVXXzF+/Hg2bNhA165dSU9PZ+nSpTz88MP079+fHj16cPfdd/Pee+/x559/Fl5Kt3r1anr06FH4Wvfffz+vvfYa999/P23btmXVqlUcOHCg2Nn9/f25/vrreeONN8jNzaVatWosXryYI0eOXLDvq6++yuLFi+nWrRsPPvggjRs3JiYmhjlz5vD7778Xufxy5MiRvPfee6xYsYLXX3+92HlE5DLMuemfiFQE594i+XLOv0WyYRhGamqq8fjjjxtVq1Y13NzcjPr16xtvvvlm4a15C2RmZhqPPvqoUblyZcPHx8fo16+fER0dfcEtgw3DcUvjMWPGGBEREYabm5sRFhZm3Hjjjcann35auE9xb5G8YsUKA7jksnr1asMwDOPQoUPGoEGDjMDAQMPT09No37698dNPPxU51ieffGJcf/31RuXKlQ0PDw+jbt26xpNPPmkkJycbhmEY2dnZxpNPPmlERkYafn5+ho+PjxEZGWl8+OGHl80oIiIiJa+8nu888sgjBmAcOnTokvtMnjzZAIzt27cbhmEYGRkZxrPPPmvUrl278LUHDRpU5Bh5eXnGm2++aTRq1Mhwd3c3goODjT59+hibN28u3CcjI8MYPXq0ERAQYPj5+RlDhgwx4uPjL3i/kyZNMgDj1KlTF2Q7fvy4MXDgQCMwMNAICAgwBg8ebJw8efKi37Njx44ZI0eONIKDgw0PDw+jTp06xpgxY4zs7OwLjtu0aVPDarUax48fv+T3RUSKz2IY581pFBEREREREZELtGrViqCgIJYtW2Z2FJFyQT2lRERERERERP7Cpk2b2LZtGyNHjjQ7iki5oZlSIiIiIiIiIpewa9cuNm/ezNSpU0lISODw4cOFd0cWkb9HM6VERERERERELmHu3Lnce++95ObmMnPmTBWkRK4hzZQSEREREREREZFSp5lSIiIiIiIiIiJS6lSUEhERERERERGRUudqdoDSZrfbOXnyJH5+flgsFrPjiIiIiJMzDIPU1FSqVq2K1VpxP8/TOZSIiIgUV3HPnypcUerkyZNERESYHUNERETKmOjoaKpXr252DNPoHEpERESu1F+dP1W4opSfnx/g+Mb4+/ubnEZEREScXUpKChEREYXnEBWVzqFERESkuIp7/lThilIF0839/f11QiUiIiLFVtEvWdM5lIiIiFypvzp/qriNEURERERERERExDQqSomIiIiIiIiISKlTUUpEREREREREREpdhespJSIiZZfNZiM3N9fsGFLOuLm54eLiYnYMERERkQrH1KLURx99xEcffcTRo0cBaNq0KRMnTqRPnz6XfM6cOXN4/vnnOXr0KPXr1+f111/nlltuKaXEIiJiBsMwiI2NJSkpyewoUk4FBgYSFhZW4ZuZi4iIiJQmU4tS1atX57XXXqN+/foYhsGXX35J//792bp1K02bNr1g/zVr1jB8+HCmTJnCrbfeyowZMxgwYABbtmyhWbNmJrwDEREpDQUFqZCQELy9vVU4kGvGMAwyMjKIj48HIDw83OREIiIiIhWHxTAMw+wQ5woKCuLNN99k9OjRFzw2dOhQ0tPT+emnnwq3dezYkZYtW/Lxxx8X6/gpKSkEBASQnJys2xmLiJQBNpuNAwcOEBISQuXKlc2OI+XU6dOniY+Pp0GDBhdcyqdzBwd9H0RERKS4inve4DSNzm02G7NmzSI9PZ1OnTpddJ+1a9fSs2fPItt69erF2rVrSyOiiIiYoKCHlLe3t8lJpDwr+PelnmUiIiIipcf0Ruc7d+6kU6dOZGVl4evry/z582nSpMlF942NjSU0NLTIttDQUGJjYy95/OzsbLKzswu/TklJuTbBRUSkVOmSPSlJ+vclIiIiUvpMnynVsGFDtm3bxvr163nooYe455572LNnzzU7/pQpUwgICChcIiIirtmxLyY1Kxe73amuiBQRERERERERcTqmz5Ryd3enXr16ALRp04aNGzfyf//3f3zyyScX7BsWFkZcXFyRbXFxcYSFhV3y+BMmTGD8+PGFX6ekpJRoYeq5BbvYfTKFB7vWoX+rqni46hbTIiJybdSqVYtx48Yxbtw4s6OIiIhIeZWXAzlpkJ3qWM4dX/Lr/G05qY6xixu4+4C7L3j4nTP2dayLM3bzBqvp82ikhJlelDqf3W4vcrnduTp16sSyZcuKnIwvWbLkkj2oADw8PPDw8LjWMS8qPTuP3w6cIikjl6e+38Fbi/czqkst7uxQkwAvt1LJICIi5vurS8EmTZrE5MmTr/i4GzduxMfH5ypTOXTv3p2WLVvy7rvv/q3jiIiIEzIMyEqGtHjITQf/6uBTBXSJcvlXWEhKcRSFilVISj2vmJT/te3if4+XPsvZYpa7T36xyu+c8fkFLZ/8Athl9rdq0oizMbUoNWHCBPr06UONGjVITU1lxowZrFy5kkWLFgEwcuRIqlWrxpQpUwB47LHH6NatG1OnTqVv377MmjWLTZs28emnn5r5Ngr5eLiy6qkezNoQxee/HyU2JYs3ft3PB8sPMqx9De67rjbVAr3MjikiIiUsJiamcDx79mwmTpzI/v37C7f5+voWjg3DwGaz4er617+Sg4ODr21QEREpG2x5kH4K0mIdBafUWEiLcyyp+dsKHsvLKvpcN28IrJG/1HSsK9U8+7VXJRWtzGIYkJXkKCQWFoeKU1gqnUJSNh6k40kqXqTaPUnDizTDsU43vEjFi/T8rx2PeZGOJ+mGJ67Y8bFk4kMWPpYsfMjEh2x8LJn4koW3JQtf8rdbss7bLwsXiwEYjveck3bt3pSr18ULWh75hSx3v3PG583y8gwA7yDwCnJs1/8314SpRan4+HhGjhxJTEwMAQEBtGjRgkWLFnHTTTcBEBUVhfWc6XqdO3dmxowZPPfcc/z73/+mfv36LFiwgGbNmpn1FooyDPyPLeXB2JmM+td/+XFnHNNWHWZ/XCr//f0IX645yq0twnnw+ro0qapbKYuIlFfnXlYeEBCAxWIp3LZy5Up69OjBwoULee6559i5cyeLFy8mIiKC8ePHs27dOtLT02ncuDFTpkwpctfZ8y/fs1gsTJs2jZ9//plFixZRrVo1pk6dym233XbV2b///nsmTpzIwYMHCQ8P55FHHuGJJ54ofPzDDz/knXfeITo6moCAALp27crcuXMBmDt3Li+88AIHDx7E29ubVq1a8cMPP/zt2V0iIuVWdtrFi0upcWe3p8VBegJwBX1rPQLAzcvx3NwMOLXPsVyMu9+Fhapzv/YMuOxLGYZBrs0gx2YnO9dGdp49f7GRnXuJcd5f7Jtnz/+66D65eQZurhY8XF1wd7Hi4WbNX5//tRWPS20v1nNdCr+2Wq+y8JCXDakxkBLjWKfGQMrJc7addPw3P7+I+DflWjzIsnqTYfF2FJQML1INT5JsHiTbPC9ZSEozzn6dhifpeGHjwllFHq5W/L3cCMhf/D1dHWsvN8Lyt/l5umI3HFcSZebYSM+xkZGTx8n8dUaOjYxsG+k5BY/nFX7taM9s4EnOOcWrc4tbWWeLXWTha8nCO3+bL46xb35xy9uSXfhcN4st/79LpmNJP/W3vs92qxs2jwBsHpWwe1XC7ukoVhlelbB4B2H1CcLiUxmrd2VcfSvj4lPZUQB20RVU5zO1KPXf//73so+vXLnygm2DBw9m8ODBJZTob8pOhfn/hKwk3Bv0ZlCbEdzRuhorD5zi098Os/bwaRZsO8mCbSfpWr8K/7i+Ll3qVdYdf0RErpBhGGTm2kr9db3cXK7Zz+xnnnmGt956izp16lCpUiWio6O55ZZbeOWVV/Dw8OCrr76iX79+7N+/nxo1alzyOC+88AJvvPEGb775Jv/5z3+48847OXbsGEFBQVecafPmzQwZMoTJkyczdOhQ1qxZw8MPP0zlypUZNWoUmzZt4tFHH+Xrr7+mc+fOJCYmsnr1asAxO2z48OG88cYbDBw4kNTUVFavXo1h6OYfIlLB2O2QkZBfaCooLF1shlOc4xK74rJYwScE/ELB95zFLwx8Q8A3zPGYTwjZVg+OJKSTnZWJkXQca3IUrinRuKVG45F+HO/043hnnMQ7J8Ex2yZ+t2O5iDSLL/EuocRYQjlpCea4EUK0vQpHbcEctQVxJs+d8vyj3s3FUrR45WqhsjWdqi5nCLOcIcRIJJhEKttPU9l+msC8BALzEvCxJRX7NWwunuS6eJPt4kOWxZsMi6NAlGp4kWL3IMnmyZk8d07neZBs97ziQtL5/Dxc8c8vJAV4ueLv6UZoQZHp3IKTl+s5xSfHY55uJXf5m2EYZOfZHUWrguJVjo2M7LzCwlZGjq1Isetk4X6XK3bl4mrkFZ2VRRa+lky8ycb3nCJXQcGroNjle85z/C3pVCINL0sOVnsu1swE3DITIKn47zHV8CLZ4kcyfqRa/Eix+pNm9SPNGkC6ix/pLgFkuviT4RpAllsA2W6B5Ll44+bqgpuLBVcXq2NtteJWMM7/2t3Viqv17D5uLo6v3VysuOZ/XfBc1/x/164uVhqF+ZXof9e/4nQ9pco0T3/oOh6WTIQVr0KzO7C4etCjYQg9Goaw83gyn6w6xMKdMaz+M4HVfybQJNyff3Srwy3Nw3FzURM3EZHiyMy10WTiolJ/3T0v9sLb/dr86nzxxRcLZwYDBAUFERkZWfj1Sy+9xPz58/nxxx8ZO3bsJY8zatQohg8fDsCrr77Ke++9x4YNG+jdu/cVZ3r77be58cYbef755wFo0KABe/bs4c0332TUqFFERUXh4+PDrbfeip+fHzVr1qRVq1aAoyiVl5fH7bffTs2aNQFo3rz5FWcQEXFauZnnFZrOneF0TqEp/RQYV/DBiZvPRQpNBeOws2PvypfthxOdmMHKffGs3L+bNYdOn/fhjTtQN385y4McqltOEWE5RXXLKapbEqhuiS/cVtmSiq+Rhm9eGnU4dOGLusBpqx/RRjDHDUfBKsYSTJw1jFOuoSS6hmJx88Ld1VHU8XC15i8u+bOW8seuZ2cxFe5zkf3drFZybWdnTuXkz6Iquj5/uy1/Fpe9cJ2dP6ur6HYbhi2bwLzThJJImOUMoRbHOsxIJCQ3ibDcREItZ/C05BbrP2224UacEUgsQcQZlYg1gog1KhGXv44liFNGINm4F+t4hd92q6XITKWLFpQ8L15c8vVwxdVJ/+60WCx4urng6eZCkM+VfU8u50qLXbFF9jv7WE6enVybgSUvE29bCj62ZHxsqfjak/G1p+BvT8XfSMWfVAJJo5KlYJ1GAOlYLQZ+lkz8yKQ68Y7Jj7b85TJyDBeS8OOM4UsSvpwxzh37Eo8fSYZjfCZ/nIRvsQqUAKuf6kFEkPff/j5fLRWlrrX2D8K6jyA5Gjb+Fzo9XPhQ8+oBvD+iNdGJGfz39yPM3hjNnpgUHpu1jTd+3c9919VmWLsIfDz0n0VEpLxr27Ztka/T0tKYPHkyP//8c2GBJzMzk6ioqMsep0WLFoVjHx8f/P39iY+Pv6pMe/fupX///kW2denShXfffRebzcZNN91EzZo1qVOnDr1796Z3794MHDgQb29vIiMjufHGG2nevDm9evXi5ptvZtCgQVSqVOmqsoiIlJrcLEg8fF6h6fyiUzxkJ1/BQS2OBuMXLTQVzG7KH3v4/vXhLiIr18aGI4ms3H+KlQfiOXyq6Kwrf09X/DzdilHsqVc4znC1cszVSqyrlZ1uLviQRWBODAFZMfhln8A34yRe6cfxTD+Be1o0LtnJVLakUtmSSksOFw1Y8Me2Wyj4XqSXVWANCIgA12tXfLgkw4CMxLOXzBVeRnfe5XQZpynm3/HkeFQiyzOUTM8Q0j1CSHMPJtWtCsluwSS5VCHRpTLJ+JFtMwqLZOcWzKx5dirn2fHPs+Pj4VJYRPK/oLiUX1DyPlto8na/djO3K4KSKnZdimEY2OwGeXaDXJudPJtBQm4utswk7OmnMTISMTISISMRS9YZrJmJWLPOYM06g2t2Eq7ZZ3DLTsI9JwkXezbuFhshJBFiSbqiHBlWH9Ks/qRa/Emx+pGCX+EsrYKCVqLdFw+jI6CiVPnh5gXdn4H/PQar34JWdzlmUJ0jIsibybc15bEb6/PNumN8ufYoJ5IyeemnPfzf0gPc1bEmo7rUIsTP06Q3ISLi3LzcXNjzYi9TXvdaOb/P0r/+9S+WLFnCW2+9Rb169fDy8mLQoEHk5ORc9jhubkV7E1gsFux2+zXLeS4/Pz+2bNnCypUrWbx4MRMnTmTy5Mls3LiRwMBAlixZwpo1a1i8eDH/+c9/ePbZZ1m/fj21a9cukTwiIlfFlgcnt8KRlXBkFUStL36TaBeP/OJS/iVz5xaXzr2MzqdKifSOiTqdwcoD8azcf4q1582GcrFaaFOjEt0aBtO9YTBNwv2vUeGi4aUfykyCpKhzlmOO9ZljjnHOOT2zjm+4yAEs4F/10k3Y/auBy1/8yVqkd9PJsz2cihSeYq/wv3GYI5df+DnrcPCrmr8Ox93VA3dAnYLlfBZL/iV1LpxzWZw7BPoA1a7sYDkZkOkoYBWuM05D5pmi285dZzkK6N72dLzt6YQQ8xcv0h+ofIXv8tpRUaoktLwL1vwHTh+EtR9AjwkX3a2SjzuP3FifB66vw7wtJ/hs9WEOJ6Tz4cpDfLb6CANbVeOB6+tQL+TqPj0RESmvLBbLNbuMzln88ccfjBo1ioEDBwKOmVNHjx4t1QyNGzfmjz/+uCBXgwYNcHFxnFS5urrSs2dPevbsyaRJkwgMDGT58uXcfvvtWCwWunTpQpcuXZg4cSI1a9Zk/vz5jB8/vlTfh4hIEXY7xO9xFKCO/AZH/3D0UTqXZ4Cj4FBYaMovLhXOcMrf5hlQqnfcysq1sf5IIiv3x/Pb/lMcTig6GyrU34PuDULo1jCYLvWqEOBVyk2UvQIdS3iLCx8zDMcfzknH8otU5xetohwNp1NOOJaotRcew+ICAdXyC1Y1Hf8NMhLyZzudM7upuLwrFyksXVB48gt33F1Ns5DEWbh7O5aA6sV/ji3PcVfHSxWtCtdnHGvvK+9Dei2VrzN6Z+HiCjc8D3PugbXvQ7v7wffSt/H2dHNhRIcaDGsXwZK9cXy66jCbj51h9qZoZm+KpmfjEP7RrS5ta1bSNE0RkXKqfv36zJs3j379+mGxWHj++edLbMbTqVOn2LZtW5Ft4eHhPPHEE7Rr146XXnqJoUOHsnbtWt5//30+/PBDAH766ScOHz7M9ddfT6VKlVi4cCF2u52GDRuyfv16li1bxs0330xISAjr16/n1KlTNG7cuETeg4jIJRmG43K8giLUkdWOQsa5PAOgVleo0x1qXw9VGjhNIeJoQrqjCHXgFGsPnyYr9+zvAlerhTY1K9G9YQjdGwbTKMzPef8+sFgcf+x6B0HVVhc+bhiO/lsFxarzC1dJUWDLOTtm9aVfy8XjgplMF5vdhKtHib1dEafh4uqYrelTxewkxaKiVElp0h/CW0LMNsdlfH1e/8unWK0WejUNo1fTMDYdTeSTVYdZujeOpXvjWbo3nlY1AvnH9XW4qUkYLld7a1IREXFKb7/9Nvfddx+dO3emSpUqPP3006SkpJTIa82YMYMZM2YU2fbSSy/x3HPP8d133zFx4kReeuklwsPDefHFFxk1ahQAgYGBzJs3j8mTJ5OVlUX9+vWZOXMmTZs2Ze/evaxatYp3332XlJQUatasydSpU+nTp0+JvAcRkSJSYs4pQq1y9Hc9l5s31OgEdbo5ilBhLS7bNLw0ZeXaWHv4NL/tP8XK/fEcPZ1R5PEwf0+651+S17leFfw9y8kt5S2W/BlpIVC97YWP2+2Oy/7OnV2VFuf4Q/v8WU5elZymqCgiV8ZiVLB7NaekpBAQEEBycjL+/iV8BfChFfD1ALC6wSObHddHX+khTqXx2erDfL/lBDl5jk9JalX25v6udRjUprqpt24UESkNWVlZHDlyhNq1a+PpqV57UjIu9++sVM8dnJi+D+JUMhLh6O9nC1EJB4o+bnWD6u3OFqGqtS2dhtrFdCR/NtTK/adYd/g02XlFZ0O1rXV2NlTDUCeeDSUicgnFPW/QTKmSVLcH1O7m+EW5cgoM/PjKDxHsy5TbWzD+poZ8ueYoX687xtHTGTy3YBfvLDnAyE61uLtTzVK5i4CIiIiIiCly0uHY2vyZUL9BzA4c91MvYIHwSEcBqk43x6wod59LHa3UZebYWHf4tKMQdeAUx86bDRUe4JgN1a1BCF3qVcavvMyGEhH5CypKlbSek2DaDbB9FnR+FEKbXNVhgv08+FevhjzUvS7fbYrms9VHOJGUyTtLD/DRbwcZ0jaC+6+rQ43K5t3KUURERETkmsjLgeMbz86EOr4J7LlF96nS8GwRqmYX05v1nsswDA4npLMy/5K89UcSC696AHBzsdCuVlBhIapBqK9mQ4lIhaSiVEmr1sbRX2rPD7DsRRgx628dzsfDlXu71ObujjVZuCuWT1cdYteJFL5ae4xv1h2jT7NwHry+DpERgdcmv4iIiIhISbPbIHYHHM7vCRW1FnKLziYiIMJxFUKdbo4m5f7h5mS9hIycPNYeOu0oRB2IJzoxs8jj1QK96NYwmO4NHL2hfD30p5iIiH4SloYbnoe9P8GBXyBqHdTo+LcP6epi5bbIqvRrEc7aQ6f5ZNVhfjtwip93xvDzzhg61A7iH93q0L1BCFY1RRcRERERZ2IYjj5Qh/Mvxzv6u+MW5ufyrnJ2JlTt66FSbadqZm0YBodOnb1T3sVmQ7WvHUT3Bo7eUPVCNBtKROR8KkqVhir1odWdsOUrWDoZ7v3lmv1CtVgsdK5Xhc71qrA3JoVpqw7z4/aTrD+SyPojidQP8eWB6+vQv2VVPFzVFF1ERERETJIU5ZgFVTAbKi226OMe/o7L8AqKUCFNnKoIBY7ZUGsOnmblAUeT8uNnLpwN5bhTXgid61bGR7OhREQuSz8lS0u3Z2DHd46pyH8ugQY3X/OXaBzuz9tDW/KvXg354o8jzNwQzZ/xaTw1dwdTF+/n3i61GdGhRvm5jayIiIiIOK+0U3D0nCLUmSNFH3f1hIgO+UWobhDeElyc688Tx2yotPzeUKfYcCSRHNvZ2VDuLlY61AmiW4NgujcMpm6wZkOJiFwJ5/qpX54FVIP2D8Ka92DZC1CvJ1itJfJSVQO9eLZvEx65sT4z1kfxxR9HiEvJ5rVf9vH+8oMMbx/BfdfVJjzAq0ReX0REREQqoKxkOLbmbBEqfnfRxy0ujn6rBZfkVW8Pbp7mZL2M9Ow8/jiYwMoDp/ht/ylOJBWdDRUR5FV4SV6nupXxdtefVCIiV0s/QUvTdY/D5i8hbhfsmgsthpToy/l7uvHPbnW5r0ttfth2gmmrD3MgLo1pq4/wxR9HuS2yKg9cX4fG4f4lmkNEREREyqHcTIhef7YIdXIrGLai+4Q2P1uEqtEJPJ3vvNMwDP6MT2PlfscleRuPJpJrMwofd3e10qF2EN0bOgpRdar4aDaUiMg1oqJUafIOgi6PwvKXYPnL0GQAuLqX+Mu6u1oZ3DaCQW2qs3L/KT5ZdYh1hxOZt/UE87ae4PoGwfzj+jp0rltZv2BFRERE5NJOHYC9PzgKUdEbwJZd9PGgumeLULW6gk8Vc3IWk2EYjJmxhYU7i/a3qhHknd8bKpiOdTQbSkSkpOina2nr+BBs+BSSjsGWL6H9A6X20haLhR6NQujRKITt0Ul8uuowv+yKYdWBU6w6cIpm1fx5oGsd+jYPx9WlZC4tFBGR4uvevTstW7bk3XffBaBWrVqMGzeOcePGXfI5FouF+fPnM2DAgL/12tfqOCJSjmSegWk3QE7q2W1+4Y5+UAVFqMAI8/JdhR+3n2ThzlhcrY6bB3XP7w1VW7OhRERKhSoPpc3dB7o95Rj/9jpkp5kSIzIikA/ubM3Kf/VgZKeaeLpZ2XUihcdmbaPbmyv54o8jpGfnmZJNRKSs69evH717977oY6tXr8ZisbBjx44rPu7GjRt58MEH/268IiZPnkzLli0v2B4TE0OfPn2u6Wudb/r06QQGBpboa4jINbTjO0dBKqAG3PIWjN0E4/fC7Z9AyxFlriCVmpXLyz/vBWBcz/p8dV977ruuNnXUrFxEpNSoKGWG1vdApdqQfgrWfWRqlBqVvXmxfzPWPHMjj/dsQGUfd04kZfLC//bQ+bXlvLVoP6dSs//6QCIiUmj06NEsWbKE48ePX/DYF198Qdu2bWnRosUVHzc4OBhvb+9rEfEvhYWF4eHhUSqvJSJlgGHApi8c4y6POmb7V6kPZbh48+7SPzmVmk2tyt48cH0ds+OIiFRIKkqZwcUNbnjOMV7zHqSfNjcPEOTjzmM96/PHMzfw8oBm1KrsTXJmLu+vOEiX15fz3IKdZOXa/vpAIiLCrbfeSnBwMNOnTy+yPS0tjTlz5jB69GhOnz7N8OHDqVatGt7e3jRv3pyZM2de9ri1atUqvJQP4M8//+T666/H09OTJk2asGTJkgue8/TTT9OgQQO8vb2pU6cOzz//PLm5uYBjptILL7zA9u3bsVgsWCyWwswWi4UFCxYUHmfnzp3ccMMNeHl5UblyZR588EHS0s7O9h01ahQDBgzgrbfeIjw8nMqVKzNmzJjC17oaUVFR9O/fH19fX/z9/RkyZAhxcXGFj2/fvp0ePXrg5+eHv78/bdq0YdOmTQAcO3aMfv36UalSJXx8fGjatCkLFy686iwiFV70Bji1F1y9SvxmPaVhX2wK09ccBWDybU3xcHUxN5CISAWlnlJmaXo7/PEuxO6E39+GXq+YnQgATzcX7upYk+Hta7BkTyyfrDrM1qgkvlkXRaifJ4/cWN/siCIijk/sczNK/3XdvIs1K8DV1ZWRI0cyffp0nn322cLLQObMmYPNZmP48OGkpaXRpk0bnn76afz9/fn555+5++67qVu3Lu3bt//L17Db7dx+++2Ehoayfv16kpOTL9prys/Pj+nTp1O1alV27tzJAw88gJ+fH0899RRDhw5l165d/PrrryxduhSAgICAC46Rnp5Or1696NSpExs3biQ+Pp7777+fsWPHFim8rVixgvDwcFasWMHBgwcZOnQoLVu25IEHrrx/ot1uLyxI/fbbb+Tl5TFmzBiGDh3KypUrAbjzzjtp1aoVH330ES4uLmzbtg03NzcAxowZQ05ODqtWrcLHx4c9e/bg6+t7xTlEJN/m6Y51szvA88KfE2WJYRhMXLAbm92gd9MwujcMMTuSiEiFpaKUWaxWuHEyfHsHbJgGHf7pVNfhu1gt9G4WTq+mYXyz7hjP/7CbGRuieKh7XTVBFxHz5WbAq1VL/3X/fdLRG7AY7rvvPt58801+++03unfvDjgu3bvjjjsICAggICCAf/3rX4X7P/LIIyxatIjvvvuuWEWppUuXsm/fPhYtWkTVqo7vxauvvnpBH6jnnnuucFyrVi3+9a9/MWvWLJ566im8vLzw9fXF1dWVsLCwS77WjBkzyMrK4quvvsLHx/H+33//ffr168frr79OaGgoAJUqVeL999/HxcWFRo0a0bdvX5YtW3ZVRally5axc+dOjhw5QkSE4/fjV199RdOmTdm4cSPt2rUjKiqKJ598kkaNGgFQv/7ZD06ioqK44447aN68OQB16ujSHJGrlnkGds9zjNuMMjXKtbBg2wk2HE3E083K8/2amB1HRKRCU3XBTPVuhJrXOW6l+9trZqe5KIvFwuC2EQT5uBOTnMWyffFmRxIRKRMaNWpE586d+fzzzwE4ePAgq1evZvTo0QDYbDZeeuklmjdvTlBQEL6+vixatIioqKhiHX/v3r1EREQUFqQAOnXqdMF+s2fPpkuXLoSFheHr68tzzz1X7Nc497UiIyMLC1IAXbp0wW63s3///sJtTZs2xcXl7CUw4eHhxMdf3e+NgvdXUJACaNKkCYGBgezd62hMPH78eO6//3569uzJa6+9xqFDhwr3ffTRR3n55Zfp0qULkyZNuqrG8iKSb8d3kJcFIU2heluz0/wtKVm5vPLzPgAeuaE+1QK9TE4kIlKxaaaUmSwW6DkZ/tsTts2Azo9CcEOzU13A082FIW0j+Pi3Q3yz7hi9ml7603QRkVLh5u2YtWTG616B0aNH88gjj/DBBx/wxRdfULduXbp16wbAm2++yf/93//x7rvv0rx5c3x8fBg3bhw5OTnXLO7atWu58847eeGFF+jVqxcBAQHMmjWLqVOnXrPXOFfBpXMFLBYLdru9RF4LHHcOHDFiBD///DO//PILkyZNYtasWQwcOJD777+fXr168fPPP7N48WKmTJnC1KlTeeSRR0osj0i5ZBhnL91re2+ZbmwO8M6SAySkZVOnig/3d61tdhwRkQpPM6XMFtEOGt0Khh2Wv2R2mku6s0MNLBZY/WcCRxLSzY4jIhWdxeK4jK60lyv8Y2zIkCFYrVZmzJjBV199xX333VfYX+qPP/6gf//+3HXXXURGRlKnTh0OHDhQ7GM3btyY6OhoYmJiCretW7euyD5r1qyhZs2aPPvss7Rt25b69etz7NixIvu4u7tjs13+RhaNGzdm+/btpKef/fn/xx9/YLVaadiwZD5MKXh/0dHRhdv27NlDUlISTZqcvdymQYMGPP744yxevJjbb7+dL774ovCxiIgI/vnPfzJv3jyeeOIJpk2bViJZRcq14xshfo+jwXnzwWan+Vv2nEzhy/zm5i/0V3NzERFnoKKUM7jhObBYYe//4Pgms9NcVESQNz3ym0B+u+7YX+wtIiIAvr6+DB06lAkTJhATE8OoUaMKH6tfvz5LlixhzZo17N27l3/84x9F7iz3V3r27EmDBg2455572L59O6tXr+bZZ58tsk/9+vWJiopi1qxZHDp0iPfee4/58+cX2adWrVocOXKEbdu2kZCQQHZ29gWvdeedd+Lp6ck999zDrl27WLFiBY888gh33313YT+pq2Wz2di2bVuRZe/evfTs2ZPmzZtz5513smXLFjZs2MDIkSPp1q0bbdu2JTMzk7Fjx7Jy5UqOHTvGH3/8wcaNG2ncuDEA48aNY9GiRRw5coQtW7awYsWKwsdE5Apsyi/0NrsdvAJNjfJ3GIbBxB92YTegb/NwutYPNjuSiIigopRzCGkMkcMd46WTHdOkndDdHWsCMGfzcTJzLv+puoiIOIwePZozZ87Qq1evIv2fnnvuOVq3bk2vXr3o3r07YWFhDBgwoNjHtVqtzJ8/n8zMTNq3b8/999/PK68UvZPrbbfdxuOPP87YsWNp2bIla9as4fnnny+yzx133EHv3r3p0aMHwcHBzJw584LX8vb2ZtGiRSQmJtKuXTsGDRrEjTfeyPvvv39l34yLSEtLo1WrVkWWfv36YbFY+OGHH6hUqRLXX389PXv2pE6dOsyePRsAFxcXTp8+zciRI2nQoAFDhgyhT58+vPDCC4Cj2DVmzBgaN25M7969adCgAR9++OHfzitSoZSjBufztpxg07EzeLu78NytKlCLiDgLi2E4aQWkhKSkpBAQEEBycjL+/v5mxzkrKQr+0wZsOXDXPEcTdCdjsxt0e3MFx89k8sagFgxp6zx3CxSR8isrK4sjR45Qu3ZtPD09zY4j5dTl/p057blDKdP3oQJa/yn88qSjwflDf5TZflLJmbncOHUlCWk5PNOnEf/sVtfsSCIi5V5xzxs0U8pZBNaAdvm3zF72ApRgY9ir5WK1cGcHx2ypb3QJn4iIiEj5dW6D8zajymxBCgqam+dQN9iH+7qoubmIiDNRUcqZdB0P7n4Qsx32zP/r/U0wpG113F2s7DiezPboJLPjiIiIiEhJOL4R4nc7Gpy3GGJ2mqu2+2QyX609CsCL/Zvh7qo/f0REnIl+KjsTnyrQOf9W1ctfBluuuXkuorKvB31bhAOaLSUiIiJSbhXMkirDDc7tdoPnFziam9/aIpwu9aqYHUlERM6jopSz6fQweFeBxMOw9Wuz01zUXfkNz3/cfpKkjByT04iIiIjINZWZBLvKfoPzuVuOsyUqydHcvG8Ts+OIiMhFqCjlbDz8oNtTjvHK1yEnw9w8F9G6RiCNw/3JzrMzd/Nxs+OIiIiIyLW0cw7kZUJIE6jezuw0VyU5I5fXftkHwLie9QkL0I0yRESckYpSzqjNKEfj87RYWP+x2WkuYLFYuLvj2YbndnuFuoGjiJjE7oQ3gJDyQ/++RPIZBmz6wjEuww3O31q8n8T0HOqH+HKvmpuLiDgtV7MDyEW4ekCPZ2H+P+CPd6HtveBVyexURfRvWZUpC/dy9HQGvx9M4PoGwWZHEpFyyt3dHavVysmTJwkODsbd3R1LGf0jSZyPYRjk5ORw6tQprFYr7u7uZkcSMdfxTfkNzj2hxVCz01yVnceT+Wa9o/fpC/2b4uaiz+FFRJyVilLOqvlg+OP/IH4P/P4u3PSC2YmK8PFw5Y421Zm+5ijfrDumopSIlBir1Urt2rWJiYnh5MmTZseRcsrb25saNWpgteqPV6ngChqcNy2bDc7tdoPnf9iFYcBtkVXpXFfNzUVEnJmKUs7K6gI3ToKZQx2X8HX4B/hXNTtVEXd1rMH0NUdZujeOk0mZVA30MjuSiJRT7u7u1KhRg7y8PGw2m9lxpJxxcXHB1dVVM/BEMpNg1/eOcRltcD5nczTbopPwcXfh2b6NzY4jIiJ/wdSi1JQpU5g3bx779u3Dy8uLzp078/rrr9OwYcNLPmf69Once++9RbZ5eHiQlZVV0nFLX4NeENERotfBb69Dv/8zO1ER9UL86FgniHWHE5m5IYonbr70fzcRkb/LYrHg5uaGm5ub2VFERMqnggbnwY0hor3Zaa5YUkZOYXPzx29qQKi/mpuLiDg7U+eo//bbb4wZM4Z169axZMkScnNzufnmm0lPT7/s8/z9/YmJiSlcjh07VkqJS5nFAj0nO8ZbvoaEg6bGuZi7O9YCYOaGaHLy1CRWREREpEw6t8F523vLZIPzNxft50xGLg1Cfbmncy2z44iISDGYWpT69ddfGTVqFE2bNiUyMpLp06cTFRXF5s2bL/s8i8VCWFhY4RIaGlpKiU1QsxPU7wWGDVa8bHaaC9zcNJRgPw8S0rJZtDvW7DgiIiIVxgcffECtWrXw9PSkQ4cObNiw4bL7v/vuuzRs2BAvLy8iIiJ4/PHHy+dMc7k6Jzaf0+B8iNlprtiO40nM2BAFwEv9m6m5uYhIGeFUP62Tk5MBCAoKuux+aWlp1KxZk4iICPr378/u3btLI555bpwIWGD3fDi51ew0Rbi5WBnevgYA36wrpzPWREREnMzs2bMZP348kyZNYsuWLURGRtKrVy/i4+Mvuv+MGTN45plnmDRpEnv37uW///0vs2fP5t///ncpJxenVTBLqulAp7vr81+x2w2eX+Bobj6wVTU61KlsdiQRESkmpylK2e12xo0bR5cuXWjWrNkl92vYsCGff/45P/zwA9988w12u53OnTtz/Pjxi+6fnZ1NSkpKkaXMCWt29hOrpc51Fz6A4e0jcLFaWH8kkQNxqWbHERERKffefvttHnjgAe69916aNGnCxx9/jLe3N59//vlF91+zZg1dunRhxIgR1KpVi5tvvpnhw4f/5ewqqSCyks9pcH7v5fd1QrM3RbP9eDJ+Hq5MuKWR2XFEROQKOE1RasyYMezatYtZs2Zddr9OnToxcuRIWrZsSbdu3Zg3bx7BwcF88sknF91/ypQpBAQEFC4RERElEb/kdZ8AVjc4vAIOrzQ7TRHhAV7c1NhxCaVmS4mIiJSsnJwcNm/eTM+ePQu3Wa1Wevbsydq1ay/6nM6dO7N58+bCItThw4dZuHAht9xyyyVfp1x8sCfFs+O7Mtvg/Ex6Dq//era5eYifmpuLiJQlTlGUGjt2LD/99BMrVqygevXqV/RcNzc3WrVqxcGDF28CPmHCBJKTkwuX6OjoaxG59AXVdjSdBMdsKcMwN8957upYE4B5W06Qlp1nchoREZHyKyEhAZvNdkFPzdDQUGJjL97fccSIEbz44otcd911uLm5UbduXbp3737Zy/fKzQd7cnmGAZunO8ZtRpW5BudvLNpPUkYujcL8GNmpptlxRETkCplalDIMg7FjxzJ//nyWL19O7dq1r/gYNpuNnTt3Eh4eftHHPTw88Pf3L7KUWdc/CW4+cHIL7P2f2WmK6Fy3MnWq+JCWnceCrSfMjiMiIiLnWLlyJa+++ioffvghW7ZsYd68efz888+89NJLl3xOuflgTy7vxGaI2+VocB451Ow0V2RbdBKzNjqam7/Yvxmuam4uIlLmmPqTe8yYMXzzzTfMmDEDPz8/YmNjiY2NJTMzs3CfkSNHMmHChMKvX3zxRRYvXszhw4fZsmULd911F8eOHeP+++834y2ULt8Q6DTGMV72IticZ0aS1WrhzvzZUt+sO4bhZDO5REREyosqVarg4uJCXFxcke1xcXGEhYVd9DnPP/88d999N/fffz/Nmzdn4MCBvPrqq0yZMgW73X7R55SrD/bk0jaXzQbnNrvBxB8czc1vb12N9rUvf6MkERFxTqYWpT766COSk5Pp3r074eHhhcvs2bML94mKiiImJqbw6zNnzvDAAw/QuHFjbrnlFlJSUlizZg1NmjQx4y2Uvs5jwSsITv8J22eYnaaIQa2r4+lmZV9sKpuPnTE7joiISLnk7u5OmzZtWLZsWeE2u93OsmXL6NSp00Wfk5GRgdVa9LTPxcUFQB8kVWRZybBrnmPcZpSpUa7UzA1R7Chobt6nsdlxRETkKrma+eLFOQlauXJlka/feecd3nnnnRJKVAZ4BkDXJ2Dxs7DyNWg+GNy8zE4FQIC3G/0jqzF7UzRfrztG21r6xEpERKQkjB8/nnvuuYe2bdvSvn173n33XdLT07n3Xkf/yZEjR1KtWjWmTJkCQL9+/Xj77bdp1aoVHTp04ODBgzz//PP069evsDglFdCO7yA3A4IbQUQHs9MU2+m0bN5ctB+AJ25uQLCfh8mJRETkaplalJKr1O5+WPcRpByHjZ9B50fMTlToro41mb0pmoU7Y3j+1iZU8dVJgoiIyLU2dOhQTp06xcSJE4mNjaVly5b8+uuvhc3Po6KiisyMeu6557BYLDz33HOcOHGC4OBg+vXrxyuvvGLWWxCzleEG52/8up/kzFwah/sX3mxHRETKJotRweZsp6SkEBAQQHJyctnujbD1G/hhjOPa/8e2O2ZQOYn+H/zB9ugknuzVkDE96pkdR0RE5G8pN+cOf5O+D+XM8c3w2Q2OBufj94J32ZjhviXqDLd/uAaAuf/spJn5IiJOqrjnDbpFRVnVYhhUaQiZZ+CP98xOU8Td+Z9YzVgfhc1eoWqeIiIiImVDQYPzJgPKTEHKZjd4fsEuAAa1qa6ClIhIOaCiVFnl4go3Pu8Yr/sQUuMuv38purVFOIHebpxIymTl/niz44iIiIjIubKSYdf3jnEZanA+Y/0xdp9Mwc/TlWf6NDI7joiIXAMqSpVljW6Fam0dDSpXvWl2mkKebi4MaRsBwNfrjpmcRkRERESK2DnnbIPzGh3NTlMsCec0N3+yV0P1LRURKSdUlCrLLBboOdkx3vwFJB42Nc65RrSvAcBvB05x7HS6yWlEREREBHA0ON803TEuQw3OX/9lHylZeTSt6s+dHdTcXESkvFBRqqyr3RXq3gj2PFjxqtlpCtWq4sP1DYIxDEdvKRERERFxAie2QNxOcPGAFkPNTlMsm48lMmfzcQBeGtAMF2vZKKSJiMhfU1GqPOg5ybHeOQdidpib5RwFDc+/2xRNVq7N5DQiIiIiUtjgvOmAMtHgPM9m5/kFuwEY2jaC1jUqmZxIRESuJRWlyoPwSGh2h2O8/CVzs5zjhkYhVAv04kxGLgt3xpgdR0RERKRiy0o5p8H5veZmKaZv10exJyaFAC83nurd0Ow4IiJyjakoVV70eBasrvDnYjj6h9lpAHCxWhjRwdFbSg3PRURERExW0OC8SsMy0eD8VGo2by0+29y8spqbi4iUOypKlReV60LrkY7x0smOJpZOYEjbCNxcLGyNSmLXiWSz44iIiIhUTIZx9tK9MtLg/LVf9pGalUfzagEMz7+JjoiIlC8qSpUn1z8Frl5wfAPs/8XsNAAE+3nQu1k4AN9otpSIiIiIOU5ugdj8BueRw8xO85c2Hk3k+y3HsVjU3FxEpDxTUao88Q+Hjg85xsteBLtzNBcvaHi+YNsJkjNzTU4jIiIiUgFtnu5Yl4EG547m5rsAGNYugpYRgeYGEhGREqOiVHnT5THwDIRTe2HHbLPTANCuViUahvqRlWtn3pbjZscRERERqViyUmBnQYPzUaZGKY6v1x1jX2wqgd5uPNmrkdlxRESkBKkoVd54BcJ1jzvGK16FvGxT4wBYLBbu6uSYLfX1umMYTtLvSkRERKRC2DkHctPzG5x3MjvNZcWnZPH24gMAPNWrEUE+7iYnEhGRkqSiVHnU/kHwC4fkaNj0udlpABjYqho+7i4cPpXO2kOnzY4jIiIiUjGUsQbnU37ZR2p2HpHVAxjaLsLsOCIiUsJUlCqP3L2h+zOO8ao3ITvV3DyAr4crA1tXAxyzpURERESkFJzcWmYanK8/fJr5W09gscCL/dXcXESkIlBRqrxqeRdUrgcZp2HN+2anAeCu/Ibni/fEEZucZXIaERERkQqgYJZUk/5O3eA812Zn4g+7ARjevgaRam4uIlIhqChVXrm4wg3POcZr34e0U+bmARqF+dO+VhA2u8HMDVFmxxEREREp38pQg/Mv1xxlf1wqlbzdePLmhmbHERGRUqKiVHnWuD+Et4ScNFg91ew0AIUNz2dtjCLXZjc5jYiIiEg5tmtufoPzBlCzs9lpLikuJYt3l/4JwNO9G1FJzc1FRCoMFaXKM6sVek52jDf9F86Y38upd9Mwqvi6E5eSzdI9cWbHERERESm/Nk93rJ28wfmrC/eSlp1Hy4hAhrRVc3MRkYpERanyrm4PqN0NbDmwcorZaXB3tRbeSUUNz0VERERKyIktELM9v8H5cLPTXNLaQ6f5YdtJLBZ4eUAzrGpuLiJSoagoVRH0nORYb58FcXvMzYKjeaXVAmsOneZgvPl3BhQREREpdwpmSTlxg3NHc/NdANzVoSbNqgWYnEhEREqbilIVQbU20Pg2wIDlL5mdhuqVvLmhUSgA36xTw3MRERGRayo7FXbOdYyduMH59D+O8md8GkE+7vxLzc1FRCokFaUqihsngsUF9i+EqPVmp+Hu/Ibn3285TkZOnslpRERERMqRnXMcDc4r13faBuexyVm8u/QAAM/0aUSAt5vJiURExAwqSlUUVepDqzsd46WTwTBMjdO1XhVqVvYmNSuPH7edNDWLiIiISLlSBhqcv7JwL+k5NlrXCGRQ6+pmxxEREZOoKFWRdHvG0ewyag38ucTUKFarhbs6OGZLfbX2GIbJRTIRERGRcuHk1vwG5+7QcoTZaS5qzcEE/rf9JFYLvNhfzc1FRCoyFaUqkoBq0OFBx3jZC2C3mxpnUJvquLta2ROTwtboJFOziIiIiJQLTt7gPCfPzsQfdwNwd0c1NxcRqehUlKporhsPHgEQtwt2fW9qlEo+7vRrURWAb9YeMzWLiIiISJlXBhqcf/HHEQ7Gp1HZx53xam4uIlLhqShV0XgHQZdHHeMVL0NejqlxChqe/7QzhsR0c7OIiIiIlGk750JOWn6D8y5mp7lATHIm/7fsTwAm3NKYAC81NxcRqehUlKqIOj4EPiFw5ihs+dLUKJHVA2heLYCcPDtzNkWbmkVERESkTHPyBucv/7SXjBwbbWtW4vZW1cyOIyIiTkBFqYrI3Qe6PeUY//YGZKeZFsVisXB3R8dsqW/WH8NuV8NzERERkSt2civEbHM0OI8cbnaaC6z+8xQ/74xRc3MRESlCRamKqs0oqFQb0uNh/UemRukXWRV/T1eiEzP57c9TpmYRERERKZMKZkk1vg18Kpsa5XzZeTYm/eBobj6yUy2aVPU3OZGIiDgLFaUqKhc3uOE5x/iP9yAj0bQoXu4uDGoTAajhuYiIiMgVO7fBedt7zc1yEf/9/QiHE9Kp4uvB+JsbmB1HRESciIpSFVnT2yG0OWSnwOqppka5s2MNAJbvjyc6McPULCIiIiJlyq7v8xuc13O6BucnkjL5z7KDADzbtxH+nmpuLiIiZ6koVZFZrdBzkmO8YRokHzctSt1gX66rVwXDgJkbokzLISIiIlLmbPrCsXbCBucv/7SHzFwb7WsFMaClmpuLiEhRKkpVdPV6Qs3rwJYNK18zNcpd+Q3PZ2+MJjvPZmoWERERkTKhSIPzEWanKeK3A6f4ZVcsLlYLLw5oisXJCmYiImI+U4tSU6ZMoV27dvj5+RESEsKAAQPYv3//Xz5vzpw5NGrUCE9PT5o3b87ChQtLIW05ZbGcnS217Vs49dff/5LSs3EIYf6enE7P4dddsablEBERESkzNn/pWDtZg/PsPBuTf3Q0Nx/VuRaNwtTcXERELmRqUeq3335jzJgxrFu3jiVLlpCbm8vNN99Menr6JZ+zZs0ahg8fzujRo9m6dSsDBgxgwIAB7Nq1qxSTlzMR7aFhXzDssPwl02K4ulgZ3t7RW+prNTwXERERubzsNNg5xzFuM8rUKOf7bPURjiSkE+znwbie9c2OIyIiTspiGIZhdogCp06dIiQkhN9++43rr7/+ovsMHTqU9PR0fvrpp8JtHTt2pGXLlnz88cd/+RopKSkEBASQnJyMv78+sSkUvxc+6uwoTN2/HKq3MSVGXEoWXV5bTp7d4JfHutI4XP+NRETEXDp3cND3wQltng7/ewyC6sIjm52mn9TxMxn0fPs3snLt/N+wlvRXLykRkQqnuOcNTtVTKjk5GYCgoKBL7rN27Vp69uxZZFuvXr1Yu3ZtiWYr90IaQ+Rwx3jpJDCpVhnq70mvpmEAfLNOs6VERERELmnzdMfayRqcv/TTHrJy7XSoHcRtkVXNjiMiIk7MaYpSdrudcePG0aVLF5o1a3bJ/WJjYwkNDS2yLTQ0lNjYi/cgys7OJiUlpcgil9D9GUeTzKOr4dBy02IUNDyfv/UEqVm5puUQERERcVontzmanLu4Q8s7zU5TaMX+eBbtjsPFauGlAc3U3FxERC7LaYpSY8aMYdeuXcyaNeuaHnfKlCkEBAQULhEREdf0+OVKYA1od79jvOwFsNtNidGxThD1QnzJyLExf+sJUzKIiIiIOLUtBQ3O+zlNg/Os3LPNze/rUosGoX4mJxIREWfnFEWpsWPH8tNPP7FixQqqV69+2X3DwsKIi4srsi0uLo6wsLCL7j9hwgSSk5MLl+jo6GuWu1zq+gS4+0HMdtizwJQIFouFuzqcbXjuRG3PRERERMyXnQY7nK/B+bRVhzl2OoNQfw8e69nA7DgiIlIGmFqUMgyDsWPHMn/+fJYvX07t2rX/8jmdOnVi2bJlRbYtWbKETp06XXR/Dw8P/P39iyxyGT5VoPMjjvHyl8FmzuVzt7epjpebC3/Gp7H+SKIpGURERESc0q7vISfV0eC8Vlez0wAQnZjB+ysOAvBs3yb4erianEhERMoCU4tSY8aM4ZtvvmHGjBn4+fkRGxtLbGwsmZmZhfuMHDmSCRMmFH792GOP8euvvzJ16lT27dvH5MmT2bRpE2PHjjXjLZRPnR4G7yqQeAi2fm1KBH9PNwa0ctypRQ3PRURERM7hhA3OX/jfHrLz7HSqU5l+LcLNjiMiImWEqUWpjz76iOTkZLp37054eHjhMnv27MJ9oqKiiImJKfy6c+fOzJgxg08//ZTIyEjmzp3LggULLtscXa6Qhx9c/6RjvPJ1yMkwJcZdHR2X8P26K5b41CxTMoiIiIg4lZjtcHILWN2g5Qiz0wCwbG8cS/fG4Wq18GL/pmpuLiIixWbqvNri9ApauXLlBdsGDx7M4MGDSyCRFGp7L6z7AJKiYMMncN3jpR6hadUA2tSsxOZjZ5i9IZpHbqxf6hlEREREnErBLKnG/RxtF0yWlWtj8v8czc1HX1eb+mpuLiIiV8ApGp2LE3L1gB7POsa/vwOZZ0yJUTBbasaGKPJs5twNUERERMQpnNvgvO295mbJ9/Fvh4hOzCTM35NH9QGiiIhcIRWl5NKaD4aQJpCVDL+/a0qEPs3CCfJxJyY5i2X74k3JICIiIuIUds/Lb3BexykanEedzuDDlYcAeP7WJvioubmIiFwhFaXk0qwucONEx3j9x5BystQjeLq5MKRtBKCG5yIiIlLBbfrCsXaSBucv/G83OXl2rqtXhVuah5kdR0REyiAVpeTyGvSGiA6QlwUbPzMlwp0damCxwOo/EziSkG5KBhERERFTFWlwfqfZaVi6J45l++Jxc7Ew+TY1NxcRkaujopRcnsUCHR9yjLd+C7a8Uo8QEeRNj4YhAHyr2VIiIiJSEW3+0rF2ggbn5zY3v79rHeqF+JqaR0REyi4VpeSvNewL3lUgLRb+XGRKhIKG53M2Hyczx2ZKBhEREWfywQcfUKtWLTw9PenQoQMbNmy47P5JSUmMGTOG8PBwPDw8aNCgAQsXLiyltPK3ZKfBju8c4zajTI0C8OHKQxw/k0nVAE8euaGe2XFERKQMU1FK/pqrO7Qc4RgX3Ia4lHVrEEL1Sl4kZ+byvx2l39tKRETEmcyePZvx48czadIktmzZQmRkJL169SI+/uI3BcnJyeGmm27i6NGjzJ07l/379zNt2jSqVatWysnlqjhRg/OjCel8/NvZ5ube7mpuLiIiV09FKSme1vc41geXQvLxUn95F6uFOzvUBHQJn4iIyNtvv80DDzzAvffeS5MmTfj444/x9vbm888/v+j+n3/+OYmJiSxYsIAuXbpQq1YtunXrRmRkZCknl6tS8KFgm1FgNff0vaC5edf6VejdTM3NRUTk71FRSoqnSj2oeR0Ydtj6jSkRhrStjruLle3Hk9kenWRKBhEREbPl5OSwefNmevbsWbjNarXSs2dP1q5de9Hn/Pjjj3Tq1IkxY8YQGhpKs2bNePXVV7HZLn1JfHZ2NikpKUUWMUHMDjix2dHgPHKEqVF2n0xmxf5TuFotvKDm5iIicg2oKCXFV9DDYMvXYC/9vk6VfT3o2yIcgG80W0pERMqYWrVq8eKLLxIVFfW3jpOQkIDNZiM0NLTI9tDQUGJjYy/6nMOHDzN37lxsNhsLFy7k+eefZ+rUqbz88suXfJ0pU6YQEBBQuERERPyt3HKVCmZJNb4VfINNjTJrQzQAvZqGUSdYzc1FROTvU1FKiq9xP/CqBCnH4eAyUyLc1dFxCd+P20+SlJFjSgYREZGrMW7cOObNm0edOnW46aabmDVrFtnZ2aXy2na7nZCQED799FPatGnD0KFDefbZZ/n4448v+ZwJEyaQnJxcuERHR5dKVjlHTrrTNDjPzLGxYOsJAIa3r2FqFhERKT9UlJLic/OEFsMc4y1fmhKhdY1AGof7k51nZ+7m0u9tJSIicrXGjRvHtm3b2LBhA40bN+aRRx4hPDycsWPHsmXLlmIfp0qVKri4uBAXF1dke1xcHGFhF+/xEx4eToMGDXBxcSnc1rhxY2JjY8nJufiHPB4eHvj7+xdZpJTtOrfB+fWmRvlpx0lSs/OICPKic93KpmYREZHyQ0UpuTJt8hue7/8FUi9+iUBJslgs3J0/W+qbdcew241SzyAiIvJ3tG7dmvfee4+TJ08yadIkPvvsM9q1a0fLli35/PPPMYzL/25zd3enTZs2LFt2dtay3W5n2bJldOrU6aLP6dKlCwcPHsRutxduO3DgAOHh4bi7u1+bNybXXsGle63vMb3B+ayNjplyw9rVwGpVLykREbk2VJSSKxPSGCI6gGGDbd+aEqF/y6r4ebhy9HQGfxxKMCWDiIjI1crNzeW7777jtttu44knnqBt27Z89tln3HHHHfz73//mzjvv/MtjjB8/nmnTpvHll1+yd+9eHnroIdLT07n33nsBGDlyJBMmTCjc/6GHHiIxMZHHHnuMAwcO8PPPP/Pqq68yZsyYEnuf8jfF7oQTmxwNzlv+9b+JkrQ/NpXNx87gYrUwuE11U7OIiEj54mp2ACmDWt8D0eth85fQ5fFS/+TOx8OVO9pUZ/qao3y99hhd65vb9FNERKQ4tmzZwhdffMHMmTOxWq2MHDmSd955h0aNGhXuM3DgQNq1a/eXxxo6dCinTp1i4sSJxMbG0rJlS3799dfC5udRUVFYz/n9HBERwaJFi3j88cdp0aIF1apV47HHHuPpp5++9m9Urg0nanA+c4OjOX/PxiGE+HuamkVERMoXFaXkyjUdAL8+A0nH4MhvULdHqUe4q2MNpq85ytK9cZxMyqRqoFepZxAREbkS7dq146abbuKjjz5iwIABuLm5XbBP7dq1GTZsWLGON3bsWMaOHXvRx1auXHnBtk6dOrFu3boryiwmcaIG51m5NuarwbmIiJQQXb4nV87dB5oPdoxNanheL8SPjnWCsBtnP70TERFxZocPH+bXX39l8ODBFy1IAfj4+PDFF1+UcjJxOrvmQXYKVKpteoPzX3bFkJyZS7VAL81OFxGRa05FKbk6BZ/a7f0J0s3p63R3x1oAzNwQTU6e/fI7i4iImCw+Pp7169dfsH39+vVs2rTJhETitAou3WtjfoPzmRscDc6HtovARQ3ORUTkGlNRSq5OeAuo2grsubBthikRbm4aSrCfBwlp2SzeU/p3AhQREbkSY8aMITo6+oLtJ06cUMNxOatIg/O7TI1yMD6NDUcSsVpgcFs1OBcRkWtPRSm5eq3vcay3fAV/cfvqkuDmYi3sbfD12mOl/voiIiJXYs+ePbRu3fqC7a1atWLPnj0mJBKntDm/NUKjvqY3OJ+90dEi4YZGIYQHqH+niIhceypKydVrPgjcfOD0n3BsjSkRhrd3TCVffySRA3GppmQQEREpDg8PD+Li4i7YHhMTg6ur7j0j5Dc4n+0Ym9zgPDvPxtzNxwEY1k4NzkVEpGSoKCVXz8MPmt/hGJvU8Dw8wIuejUMA+GadZkuJiIjzuvnmm5kwYQLJycmF25KSkvj3v//NTTfdZGIycRq75+c3OK8FtbuZGmXx7jjOZOQS5u9J94ZqcC4iIiVDRSn5e1qPcqx3L4CMRFMiFDQ8n7flBOnZeaZkEBER+StvvfUW0dHR1KxZkx49etCjRw9q165NbGwsU6dONTueOIPCBuejnKDBuePSvSFtq+Pqoj8ZRESkZOg3jPw91VpDaDOwZcOO70yJ0LluZepU8SEtO48F206YkkFEROSvVKtWjR07dvDGG2/QpEkT2rRpw//93/+xc+dOIiIizI4nZovdBcc3gtUVWt5papSjCemsOXQaiwWGtNO/TRERKTlqYCB/j8XiaHj+y5OOS/g6/MOxrRRZrRbu7FiTl37aw9drjzGifQ0spZxBRESkOHx8fHjwwQfNjiHOqGCWVKO+4BtiapRZGx13iby+fjDVK3mbmkVERMo3FaXk72sxBJY8D/F74PgmiGhX6hEGta7Om4v2sS82lc3HztC2VlCpZxARESmOPXv2EBUVRU5OTpHtt912m0mJxHQ5Gec0OL/X3Ch5duZudhSlCu5yLCIiUlJUlJK/zysQmg6E7TMdn/KZUJQK8Hajf2Q1Zm+K5ut1x1SUEhERp3P48GEGDhzIzp07sVgsGIYBUDi712azmRlPzOREDc6X7Y0jIS2HYD8Pbmxs7owtEREp/66qp1R0dDTHjx8v/HrDhg2MGzeOTz/99JoFkzKm9T2O9e55kJViSoS7OtYEYOHOGBLSsk3JICIicimPPfYYtWvXJj4+Hm9vb3bv3s2qVato27YtK1euNDuemGnzF45163tMb3A+I7/B+eA21XFTg3MRESlhV/WbZsSIEaxYsQKA2NhYbrrpJjZs2MCzzz7Liy++eE0DShlRoyNUaQi5GbBzjikRmlcPIDIikFybwez8XggiIiLOYu3atbz44otUqVIFq9WK1WrluuuuY8qUKTz66KNmxxOzOFGD8+jEDH4/mADAsHa6dE9EREreVRWldu3aRfv27QH47rvvaNasGWvWrOHbb79l+vTp1zKflBUWC7TJny215UvTYtydP1tqxvoobHbDtBwiIiLns9ls+Pn5AVClShVOnjwJQM2aNdm/f7+Z0cRMBedNjfqCX6ipUWZvjMYw4Lp6VahRWQ3ORUSk5F1VUSo3NxcPDw8Ali5dWtiYs1GjRsTExFy7dFK2tBgGLu4Qsx1ObjUlwq0twgn0duNEUiYr98ebkkFERORimjVrxvbt2wHo0KEDb7zxBn/88QcvvvgiderUMTmdmCInA7YXNDgfZWqUPJud7zapwbmIiJSuqypKNW3alI8//pjVq1ezZMkSevfuDcDJkyepXLnyNQ0oZYhPZWjczzHebM5sKU83F4a0jQDg63XHTMkgIiJyMc899xx2ux2AF198kSNHjtC1a1cWLlzIe++9Z3I6McXu+ZCdDIE1oXZ3U6Ms3xdPfGo2lX3cuamJuTO2RESk4riqotTrr7/OJ598Qvfu3Rk+fDiRkZEA/Pjjj4WX9UkFVdDwfOdcyE4zJcKI/E/3fjtwimOn003JICIicr5evXpx++23A1CvXj327dtHQkIC8fHx3HDDDSanE1Nsnu5YtzG/wfms/H6cg9pUx91VDc5FRKR0XNVvnO7du5OQkEBCQgKff/554fYHH3yQjz/++JqFkzKoVlcIqgM5qY5P/8yIUMWH6xsEYxiO3lIiIiJmy83NxdXVlV27dhXZHhQUhMViMSmVmCpuNxzfkN/g/C5To5zb9mBouwhTs4iISMVyVUWpzMxMsrOzqVSpEgDHjh3j3XffZf/+/YSEhFzTgFLGWK3QeqRjXPDpnwkKGp5/tymarFybaTlEREQA3NzcqFGjBjabfidJvoLzpIa3mN7g/LuN0dgN6FgniDrBvqZmERGRiuWqilL9+/fnq6++AiApKYkOHTowdepUBgwYwEcffXRNA0oZ1PJOx6d+JzY5PgU0wQ2NQqgW6MWZjFwW7lTzfRERMd+zzz7Lv//9bxITE82OImZzogbnNruhBuciImKaqypKbdmyha5duwIwd+5cQkNDOXbsGF999ZUadQr4hkDDPo6xSQ3PXawWRnRwnFip4bmIiDiD999/n1WrVlG1alUaNmxI69atiyxSgexZcLbBeZ0epkb57UA8MclZBHq70atpmKlZRESk4nG9midlZGTg5+cHwOLFi7n99tuxWq107NiRY8eKXwBYtWoVb775Jps3byYmJob58+czYMCAS+6/cuVKevS48Bd3TEwMYWH6JepU2oyCvf+DHbPgphfAzavUIwxpG8G7Sw+wNSqJXSeSaVYtoNQziIiIFLjcOY5UME7U4HzmBscsqTtaV8fTzcXULCIiUvFcVVGqXr16LFiwgIEDB7Jo0SIef/xxAOLj4/H39y/2cdLT04mMjOS+++4rvBtNcezfv7/I66iPlROqcwME1IDkKNjzA0QOK/UIwX4e9G4Wzv+2n+Sbdcd47Y4WpZ5BRESkwKRJk8yOIM4gbg9Er3eKBudxKVks3+docD68vRqci4hI6buqj2YmTpzIv/71L2rVqkX79u3p1KkT4Jg11apVq2Ifp0+fPrz88ssMHDjwil4/JCSEsLCwwsVq8idMchFWK7S+2zE26RI+ONvw/IdtJ0nOzDUth4iIiAhwToPzPqY3OJ+zKRqb3aBdrUrUC/EzNYuIiFRMV1XNGTRoEFFRUWzatIlFixYVbr/xxht55513rlm4S2nZsiXh4eHcdNNN/PHHHyX+enKVWt4JFitErYFTB0yJ0K5WJRqG+pGZa2PeluOmZBAREQGwWq24uLhccpEKICfD0doAoM29pkax2w1mbXRcujesnRqci4iIOa7q8j2gcJbS8eOOP/SrV69O+/btr1mwiwkPD+fjjz+mbdu2ZGdn89lnn9G9e3fWr19/yQah2dnZZGdnF36dkpJSohnlHAHVoH4vOPALbPkSer1S6hEsFgt3darJ8wt28fW6Y4zqXAuLxVLqOURERObPn1/k69zcXLZu3cqXX37JCy+8YFIqKVV7FkBWMgTWML3B+e8HEzh+JhN/T1f6tgg3NYuIiFRcV1WUstvtvPzyy0ydOpW0tDQA/Pz8eOKJJ3j22WdL7HK6hg0b0rBhw8KvO3fuzKFDh3jnnXf4+uuvL/qcKVOm6ETPTG3ucRSlts2AGyeCq0epRxjYqhqvLdzL4VPprD10ms71qpR6BhERkf79+1+wbdCgQTRt2pTZs2czevRoE1JJqSq4dK+1MzQ4jwIc50lqcC4iIma5qt+Gzz77LO+//z6vvfYaW7duZevWrbz66qv85z//4fnnn7/WGS+rffv2HDx48JKPT5gwgeTk5MIlOjq6FNMJ9W4Cv3DITIR9P5kSwdfDlYGtqwHw9bri3x1SRESkNHTs2JFly5aZHUNK2rkNzluZ2+D8VGo2S/bEATC8gy7dExER81xVUerLL7/ks88+46GHHqJFixa0aNGChx9+mGnTpjF9+vRrHPHytm3bRnj4pacce3h44O/vX2SRUuRyzomXiQ3P78pveL54TxxxKVmm5RARETlXZmYm7733HtWqVTM7ipS0LfnnQQ37gF+YqVHmbj5Ont2gZUQgjcJ0biwiIua5qsv3EhMTadSo0QXbGzVqRGJiYrGPk5aWVmSW05EjR9i2bRtBQUHUqFGDCRMmcOLECb766isA3n33XWrXrk3Tpk3Jysris88+Y/ny5SxevPhq3oaUllZ3w6q34MhvkHgYguqUeoRGYf60rxXEhqOJzNwQxbieDUo9g4iIVGyVKlUq0tfQMAxSU1Px9vbmm2++MTGZlLjcTNg+0zFuM8rUKI4G545L90a01ywpEREx11UVpSIjI3n//fd57733imx///33adGiRbGPs2nTJnr0ONvkcfz48QDcc889TJ8+nZiYGKKiogofz8nJ4YknnuDEiRN4e3vTokULli5dWuQY4oQq1YS6N8ChZbDlK+g52ZQYd3WqWViUGtOjHm4u5vZyEBGRiuWdd94pUpSyWq0EBwfToUMHKlWqZGIyKXG7F5zT4PwGU6OsO3yaY6cz8PVw5dZINTgXERFzXVVR6o033qBv374sXbqUTp06AbB27Vqio6NZuHBhsY/TvXt3DMO45OPnXwr41FNP8dRTT11NZDFbm3scRamt30KPZ8HFrdQj9G4aRhVfd+JSslm6J44+zXUiJiIipWfUqFFmRxCzOFGD8xn5Dc77t6yKt/tV34hbRETkmriq34rdunXjwIEDDBw4kKSkJJKSkrj99tvZvXv3Je+CJxVcgz7gEwzp8XDgV1MiuLtaGdouAlDDcxERKX1ffPEFc+bMuWD7nDlz+PJL8/ouSgmL3wvR68DiYnqD89Np2Szend/gXJfuiYiIE7jqj2qqVq3KK6+8wvfff8/333/Pyy+/zJkzZ/jvf/97LfNJeeHqDi3vdIxNbHg+vH0NrBZYc+g0B+PTTMshIiIVz5QpU6hSpcoF20NCQnj11VdNSCSlomCWlBM0OJ+35QQ5NjvNqwXQrFqAqVlERETgbxSlRK5Y65GO9cGlkBR1+X1LSPVK3tzQKBSAb9drtpSIiJSeqKgoateufcH2mjVrFumhKeVIkQbn95oaxTAMZuY3ONcsKRERcRYqSknpqVwXanUFDNhq3l2G7u5UE3DcDjkjJ8+0HCIiUrGEhISwY8eOC7Zv376dypUrm5BIStyeHxwNzgNqOG76YqINRxI5fCodb3cXbmtZ1dQsIiIiBVSUktJVcBvkrd+A3WZKhK71qlCzsjepWXnM33rClAwiIlLxDB8+nEcffZQVK1Zgs9mw2WwsX76cxx57jGHDhpkdT0rCpi8c6zYjTW9wPmtjNAC3RVbF10MNzkVExDlc0W+k22+//bKPJyUl/Z0sUhE0uhW8giDlhOMyvga9Sj2C1WphZKdavPTTHt5b9icDW1XT3WdERKTEvfTSSxw9epQbb7wRV1fH7x273c7IkSPVU6o8ittztsF5S3MbnCdl5PDzzhgAhunSPRERcSJX9Jd4QMDlGyIGBAQwcuTIvxVIyjk3T4gcDus+cDT+NKEoBXBnhxp8/vsRTiRlMm3VER7rWd+UHCIiUnG4u7sze/ZsXn75ZbZt24aXlxfNmzenZs2aZkeTkrD+I8e6UV/wDzc1yrwtJ8jJs9M43J/I6mpwLiIizuOKilJffPFFSeWQiqTNPY6i1IFFkBJjyomap5sLT/dpxKMzt/LJqkMMbx9BiL9nqecQEZGKp379+tSvrw9DyrX0BNg+2zHuNMbUKIZhMKuwwXkEFovF1DwiIiLnUk8pKX3BDSGiIxg22GZew/N+LcJpGRFIRo6Nt5ccMC2HiIhUDHfccQevv/76BdvfeOMNBg8ebEIiKTGbvgBbNlRtBREdTI2yJeoMB+LS8HSz0r9lNVOziIiInE9FKTFHQcPzLV+B3W5KBIvFwvO3Ngbgu03R7ItNMSWHiIhUDKtWreKWW265YHufPn1YtWqVCYmkROTlwMZpjnHHMWDyzKSZGxwNzm9tUZUALzdTs4iIiJxPRSkxR5P+4BEASVFweIVpMdrUDOKW5mHYDXjl572m5RARkfIvLS0Nd3f3C7a7ubmRkqIPRsqN3fMhLQ78wh3nOyZKzszlpx0nAceleyIiIs5GRSkxh7s3tBjiGG/50tQoT/duhJuLhdV/JrByf7ypWUREpPxq3rw5s2fPvmD7rFmzaNKkiQmJ5JozDEffTIB294PrhUXI0vTjthNk5dppEOpL6xqVTM0iIiJyMVfU6Fzkmmpzj2N6+76FkHYKfINNiVGzsg/3dKrFZ78f4dWFe7muXhVcXVSvFRGRa+v555/n9ttv59ChQ9xwww0ALFu2jBkzZjB37lyT08k1EbUWYraDqye0udfUKIZhMCP/0r1h7WqowbmIiDgl/eUt5glrDtXagD0Xts8wNcojN9Qn0NuNA3FpfLfpuKlZRESkfOrXrx8LFizg4MGDPPzwwzzxxBOcOHGC5cuXU69ePbPjybWw7kPHOnIY+FQ2NcqO48nsjUnB3dXK7a3V4FxERJyTilJirtb3ONabv3RMeTdJgLcbj97guD3320v2k5adZ1oWEREpv/r27csff/xBeno6hw8fZsiQIfzrX/8iMjLS7Gjyd505Cvt+dow7PGRqFICZG6IAuKVZGIHe5l5GKCIicikqSom5mt0B7r6QeAiO/m5qlLs61qRWZW8S0nL4eOUhU7OIiEj5tWrVKu655x6qVq3K1KlTueGGG1i3bp3ZseTvWv8pGHaoewOENDI1Slp2Hj9uL2hwXsPULCIiIpejopSYy8PXUZgC0xueu7taeaZPYwCmrT7MyaRMU/OIiEj5ERsby2uvvUb9+vUZPHgw/v7+ZGdns2DBAl577TXatWtndkT5O7JSYMtXjnHHh83NAvy47SQZOTbqBPvQvnaQ2XFEREQuSUUpMV+bUY71nh8hI9HUKL2ahtK+VhDZeXbeWrTf1CwiIlI+9OvXj4YNG7Jjxw7effddTp48yX/+8x+zY8m1tG0G5KRClQZQ90az0xReujdcDc5FRMTJqSgl5qvaytH03JYN22eZGsVisfDcrY7ZUvO2nmDn8WRT84iISNn3yy+/MHr0aF544QX69u2Li4uL2ZHkWrLbYP1HjnGHf4LV3NPrXSeS2XkiGTcXixqci4iI01NRSsxnsZxteL7F3IbnAC2qBzKgZVUAXv55D4bJeUREpGz7/fffSU1NpU2bNnTo0IH333+fhISEv33cDz74gFq1auHp6UmHDh3YsGFDsZ43a9YsLBYLAwYM+NsZBDjwq6PJuWeg4657JiuYJdWraRiVfT1MTiMiInJ5KkqJc2gxBFy94NQ+iC7eSXVJerJ3Izxcraw/ksiSPXFmxxERkTKsY8eOTJs2jZiYGP7xj38wa9Ysqlatit1uZ8mSJaSmpl7xMWfPns348eOZNGkSW7ZsITIykl69ehEfH3/Z5x09epR//etfdO3a9WrfjpxvXf4sqTajwN3H1CgZOXn8sM3R4HyEGpyLiEgZoKKUOAfPAGh2u2NscsNzgGqBXoy+rjYAr/2yj1yb3eREIiJS1vn4+HDffffx+++/s3PnTp544glee+01QkJCuO22267oWG+//TYPPPAA9957L02aNOHjjz/G29ubzz///JLPsdls3HnnnbzwwgvUqVPn774dAYjZAUdXg8UF2j9odhp+2h5DWnYeNSt707FOZbPjiIiI/CUVpcR5FFzCt2seZCaZGgXgoe51qeLrzuGEdL5dd8zsOCIiUo40bNiQN954g+PHjzNz5swrem5OTg6bN2+mZ8+ehdusVis9e/Zk7dq1l3zeiy++SEhICKNHjy7W62RnZ5OSklJkkfMUzJJqOgACzO/fNHOj49K9Ye1qYLWqwbmIiDg/FaXEeUS0h+BGkJcJO+eYnQY/TzfG9WwAwP8t+5PkzFyTE4mISHnj4uLCgAED+PHHH4v9nISEBGw2G6GhoUW2h4aGEhsbe9Hn/P777/z3v/9l2rRpxX6dKVOmEBAQULhEREQU+7kVQmoc7JrrGHd82NwswL7YFLZGJeFqtTCoTXWz44iIiBSLilLiPJys4TnAsHYR1A/x5UxGLh+sOGh2HBERkSuWmprK3XffzbRp06hSpUqxnzdhwgSSk5MLl+jo6BJMWQZt+hxsOVC9PVRva3YaZm1w/Pe5qUkowX5qcC4iImWDilLiXCKHgYsHxO6Ek1vNToOri5V/39IYgOl/HCU6McPkRCIiUtFVqVIFFxcX4uKK3ogjLi6OsLCwC/Y/dOgQR48epV+/fri6uuLq6spXX33Fjz/+iKurK4cOHbro63h4eODv719kkXy5WbDxM8e440PmZgEyc2zM23IcgGFqcC4iImWIilLiXLyDoEl+s9fN002NUqB7w2Cuq1eFHJud137dZ3YcERGp4Nzd3WnTpg3Lli0r3Ga321m2bBmdOnW6YP9GjRqxc+dOtm3bVrjcdttt9OjRg23btumyvKuxay5kJIB/dWh8ZU3qS8LCnTGkZOVRLdCLrvWKPxtORETEbCpKifMpbHj+PWSnmZsFsFgs/PuWxlgs8POOGDYfO2N2JBERqeDGjx/PtGnT+PLLL9m7dy8PPfQQ6enp3HvvvQCMHDmSCRMmAODp6UmzZs2KLIGBgfj5+dGsWTPc3d3NfCtlj2GcbXDe/gFwcTU3DzCrsMF5hBqci4hImaKilDifWtdBUF3ISXMUppxAk6r+DM5vGvryz3swnKDflYiIVFxDhw7lrbfeYuLEibRs2ZJt27bx66+/FjY/j4qKIiYmxuSU5dTR1RC3C9y8oc09Zqfhz7hUNh49g4vVwuC2mvUmIiJli/kf7Yicz2JxnOQtmehoeO4EJ3wAT9zckP9tj2FrVBI/74zh1hZVzY4kIiIV2NixYxk7duxFH1u5cuVlnzt9+vRrH6iiWPuhY91yBHhVMjcLMGujo8F5j4YhhAV4mpxGRETkymimlDinyBFgdYMTmx1Nz51AqL8n/+hWB4DXf91Hdp7N5EQiIiJSqk4fggO/OsYd/mluFiAr18b3+Q3OR3TQLCkRESl7VJQS5+QbDI1ucYw3f2lulnM8eH0dQv09iE7M5Ms1R82OIyIiIqVp/SeAAfVvhir1zU7Dot2xJGXkEh7gSbcGIWbHERERuWIqSonzKmh4vuM7yMkwN0s+b3dXnri5IQD/WX6QxPQckxOJiIhIqchMgq3fOMYdHzY1SoGZGxwNzoe0jcBFDc5FRKQMUlFKnFedHhBYA7KTYc8PZqcpdEfr6jQO9yc1K4/3lv1pdhwREREpDVu/htx0CG4MdbqbnYbDp9JYdzgRqwWGtNOleyIiUjapKCXOy2qF1iMd483TTY1yLherhef6Ngbgm3XHOHwqzeREIiIiUqJsebD+U8e440OOm7KYbHZ+g/NuDYKpFuhlchoREZGro6KUOLeWd4HFBaLXQfw+s9MU6lKvCjc0CiHPbjDlF+fJJSIiIiVg/8+QHAXelaHFELPTkJNnZ+5mR4Pz4e1rmJxGRETk6qkoJc7NPxwa9HKMt3xlbpbz/PuWRrhYLSzZE8e6w6fNjiMiIiIlZe2HjnXb+8DN/FlJS/bEcTo9hxA/D25opAbnIiJSdplalFq1ahX9+vWjatWqWCwWFixY8JfPWblyJa1bt8bDw4N69eoxffr0Es8pJmszyrHePhNys0yNcq56IX4Mb+/o4fDyz3uw2w2TE4mIiMg1d2KzY8a21Q3ajjY7DVC0wbmriz5jFhGRssvU32Lp6elERkbywQcfFGv/I0eO0LdvX3r06MG2bdsYN24c999/P4sWLSrhpGKqej3BvxpkJsK+n8xOU8S4ng3w9XBl14kUFmw7YXYcERERudbWfexYN7vdMYPbZFGnM/j9YAIAQ9XgXEREyjhTi1J9+vTh5ZdfZuDAgcXa/+OPP6Z27dpMnTqVxo0bM3bsWAYNGsQ777xTwknFVFYXaHWXY+xEDc8Bqvh68HCPugC8uWg/mTk2kxOJiIjINZMSA7vnOcYdHzI3S75ZGx2zpLrWr0JEkLfJaURERP6eMjXfd+3atfTs2bPItl69erF27VqTEkmpaXUXYIGjq+H0IbPTFHFfl9pUC/QiJjmL//5+2Ow4IiIicq1snAb2PKjRGaq2MjsNuTY7c/IbnI9Qg3MRESkHylRRKjY2ltDQ0CLbQkNDSUlJITMz86LPyc7OJiUlpcgiZVBgDcdlfOB0Dc893Vx4qndDAD5aeYj4VOfpeyUiIiJXKScDNn3hGDvJLKlle+M5lZpNFV93bmwc+tdPEBERcXJlqih1NaZMmUJAQEDhEhGha+/LrDb3ONbbvoW8HHOznKdfi6pEVg8gPcfGO0v+NDuOiIiI/F07v3P0swysAY36mp0GOHvp3qA2Ebi7lvvTeBERqQDK1G+zsLAw4uLiimyLi4vD398fL6+L3553woQJJCcnFy7R0dGlEVVKQoPe4BMC6afgwC9mpynCarXw3K1NAJi9MYr9sakmJxIREZGrZhiw7iPHuMM/Hf0tTXb8TAa/HTgFwDA1OBcRkXKiTBWlOnXqxLJly4psW7JkCZ06dbrkczw8PPD39y+ySBnl4gat7nSMN39pbpaLaFcriN5Nw7Ab8OrCvWbHERERkat1aDmc2gfuvmdvtmKy7zYdxzCgc93K1KriY3YcERGRa8LUolRaWhrbtm1j27ZtABw5coRt27YRFeWYmjxhwgRGjhxZuP8///lPDh8+zFNPPcW+ffv48MMP+e6773j88cfNiC9maJ3/7+HQcjhzzNwsF/F0n0a4Wi38duAUq/I/zRQREZEypmCWVKu7wDPA3CxAns3Odxsds/2HqcG5iIiUI6YWpTZt2kSrVq1o1cpxN5Px48fTqlUrJk6cCEBMTExhgQqgdu3a/PzzzyxZsoTIyEimTp3KZ599Rq9evUzJLyYIqgO1uwEGbP3a7DQXqF3Fh7s71QQcs6VsdsPkRCIiInJFTh2Ag0sAC3T4h9lpAFi5/xSxKVlU8najV1M1OBcRkfLD1cwX7969O4Zx6T/ap0+fftHnbN26tQRTidNrcw8c+Q22fgPdngEXU/8ZX+CxG+vz/ebj7ItNZc6maH2iKSIiUpasz58l1fAWx4dhTqCgwfkdravj4Wp+fysREZFrpUz1lBIBoNGt4BUEqTH5n2Q6l0Bvdx69sT4AU5ccID07z+REIiIiUiwZibBtpmPc8SFzs+SLSc5k+b54QJfuiYhI+aOilJQ9rh7QcoRj7IQNzwHu7lSTGkHenErN5pPfDpkdR0RERIpjy5eQlwmhzaHWdWanAWDOpuPYDWhfK4h6Ib5mxxEREbmmVJSSsqn1PY71n4sg+YS5WS7Cw9WFZ/o0AuDT1YeJSc40OZGIiIhcli0XNkxzjDs+BBaLuXkAm91gdn6D8+EdIkxOIyIicu2pKCVlU3ADqNEZDDts+9bsNBfVp1kYbWtWIivXzluLDpgdR0RERC5nzw+QcgJ8gqH5ILPTALD6z1OcSMokwMuNPs3CzY4jIiJyzakoJWVXm/zZUlu+Brvd3CwXYbFYeLZvYwDmbT3OrhPJJicSERGRS1qX3+C83f2OVgFOYOYGR4Pzga2q4emmBuciIlL+qCglZVeT/uAZAMlRcHi52WkuqlWNSvSLrIphwCs/773s3SZFRETEJNEb4cQmcHGHtveZnQaA+JQslu11NDgfrgbnIiJSTqkoJWWXmxe0GOYYb55uapTLeapXQ9xdraw9fLrw7jkiIiLiRNZ96Fg3Hwy+IeZmyTdn83Hy7AatawTSMMzP7DgiIiIlQkUpKdsKLuHb/wukOWfBJyLIm3u71ALg1YV7ybU536WGIiIiFVZStKOfFDganDsBu91g1kbHpXuaJSUiIuWZilJStoU2hWptwZ7ntA3PAcb0qEeQjzuHTqUzK78/hIiIiDiBjdPAsEGtrhDW3Ow0AKw5dJroxEz8PFzp20INzkVEpPxSUUrKvjajHOstXzllw3MAf083xvWsD8A7S/8kJSvX5EQiIiJCTvrZFgAdHzY1yrkKGpwPaFUNb3dXk9OIiIiUHBWlpOxrdju4+0HiYTi62uw0lzS8fQ3qBPuQmJ7DhysOmR1HREREts2ArGSoVBsa9DY7DQAJadks3hMLwLD2ESanERERKVkqSknZ5+4DzQc5xlu+NDfLZbi5WPl3n8YAfP7HEaITM0xOJCIiUoHZ7bD+Y8e440NgdY7T4u83HyfXZhBZPYCmVQPMjiMiIlKinOO3r8jfVdDwfO//IP20uVku48bGIXSqU5mcPDtvLtpvdhwREZGK6+BSOH0QPPyh5Qiz0wBgGAazNkYDMEwNzkVEpAJQUUrKh6qtIDwSbDmwY5bZaS7JYrHwbN/GWCzw4/aTbItOMjuSiIhIxbTuQ8e69Ujw8DM3S751hxM5kpCOj7sL/SKrmh1HRESkxKkoJeVH6/zZUpung2GYGuVymlUL4PZW1QF4+ac9GE6cVUREpFyK2wOHV4DFCu0fNDtNoVkbHQ3Ob2tZDV8PNTgXEZHyT0UpKT+aDwY3b0g4AFHrzE5zWU/2aoinm5VNx87w665Ys+OIiIhULOs/cqwb3QqVapqbJd+Z9Bx+2ek4JxiuBuciIlJBqCgl5YenPzS93TF24obnAGEBnjzYtQ4Ar/26j5w8u8mJREREKoj0BNg+2zHu+LC5Wc4xb+sJcmx2mlb1p3k1NTgXEZGKQUUpKV/ajHKsd8+HzDOmRvkr/+hWl2A/D46dzuCrtUfNjiMiIlIxbP4CbNkQ3hJqdDQ7DeBocD5zg+PSvWHta2CxWExOJCIiUjpUlJLypXpbCGkCeVmwY47ZaS7Lx8OVJ25qAMB/lh8kKSPH5EQiIiLlXF4ObPjMMe40Bpyk+LPp2BkOxqfh5eZC/5ZqcC4iIhWHilJSvlgsZxueb/nSqRueAwxuG0GjMD+SM3N5b9lBs+OIiIiUb7vnQ1os+IZBkwFmpylUMEvq1hbh+Hu6mZxGRESk9KgoJeVPiyHg4gFxu+DEFrPTXJaL1cK/b2kMwNfrjnI0Id3kRCIiIuWUYcC6Dxzj9veDq7u5efIlZ+Ty844YAIZ3qGFyGhERkdKlopSUP95B0HSAY7xluplJiuX6BsF0axBMrs3gtV/2mR1HRESkfIpaCzHbwdUT2txndppCC7adIDvPTsNQP1pFBJodR0REpFSpKCXlU8ElfDu/h+xUc7MUw7N9G2O1wK+7Y9lwJNHsOCIiIuXPug8d6xZDwaeyuVnyndvgfHj7CDU4FxGRCkdFKSmfanaGyvUhNx12zjU7zV9qEOrH0HaOKfuv/LwHu925e2GJiIiUKWeOwr6fHeOOD5ka5VzbopPYF5uKh6uVga2qmx1HRESk1KkoJeWTxQKtRzrGW740N0sxjb+pAT7uLmw/nsz/dpw0O46IiEj5sWEaGHao0wNCGpudplDBLKm+zcMJ8FaDcxERqXhUlJLyq+UIsLrBya2OHhJOLtjPg4e61wXgjV/3k5VrMzmRiIhIOZCdClu+cow7PmxulnOkZuXyv+1qcC4iIhWbilJSfvlUgca3Osaby8ZsqdHX1SE8wJMTSZl8/scRs+OIiIiUfVu/hewUx2X99XqanabQD9tOkplro16IL21rVjI7joiIiClUlJLyrbDh+RzISTc3SzF4ubvwZK+GAHy44hAJadkmJxIRESnD7DZY/7Fj3PGfYHWeU9+CS/eGtVODcxERqbic5zezSEmo3Q0Cazo+Id29wOw0xTKgZTWaVwsgLTuPd5ceMDuOiIhI2XVgEZw5Ap6BEDnc7DSFdh5PZvfJFNxdrNzeWg3ORUSk4lJRSso3qxXa5M+WKiMNz61WC8/2dTRhnbkhmoPxqSYnEhERKaPWfehYtxkF7j6mRjnXjPxZUr2bhRHk425yGhEREfOoKCXlX8s7weIC0eshfq/ZaYqlY53K3NQkFJvd4NWF+8yOIyIiUvbE7ICjqx3nAO0fMDtNofTsPH7cdgKAYe0jTE4jIiJiLhWlpPzzC4OGfRzjMtLwHGBCn0a4Wi0s3xfPHwcTzI4jIiJSthT0kmrSHwKc5xK5/20/SXqOjVqVvelUp7LZcUREREylopRUDAUNz3fMgtwsc7MUU51gX+7qWBOAl3/ei81umJxIRESkjEiNc9zkBKDjw+ZmOc/MjdEADGtfQw3ORUSkwlNRSiqGejeCf3XIPAN7/2d2mmJ79Mb6+Hm6sjcmhe+3HDc7joiIOJEPPviAWrVq4enpSYcOHdiwYcMl9502bRpdu3alUqVKVKpUiZ49e152/zJv0+dgy4Hq7SCindlpCu05mcL26CTcXCwMauM8s7dERETMoqKUVAxWF2h9t2O8ebqpUa5EkI87j9xQD4C3Fu0nIyfP5EQiIuIMZs+ezfjx45k0aRJbtmwhMjKSXr16ER8ff9H9V65cyfDhw1mxYgVr164lIiKCm2++mRMnTpRy8lKQmwWb/usYd3zI3CznmbXR0eD8piahVPH1MDmNiIiI+VSUkoqj1V1gscKx3yHhoNlpiu2ezrWICPIiPjWbT1cdNjuOiIg4gbfffpsHHniAe++9lyZNmvDxxx/j7e3N559/ftH9v/32Wx5++GFatmxJo0aN+Oyzz7Db7SxbtqyUk5eCXd9D+inwrwaNbzM7TaHMHBvztzqKgMPb1zA5jYiIiHNQUUoqjoDqUK+nY7yl7DQ893B14enejQD45LfDxKWUjZ5YIiJSMnJycti8eTM9e/Ys3Ga1WunZsydr164t1jEyMjLIzc0lKCjokvtkZ2eTkpJSZHF6hgHrPnSM2z8ALm7m5jnHzztjSM3KIyLIiy51q5gdR0RExCk4RVHqSnoiTJ8+HYvFUmTx9PQsxbRSprUZ5VhvmwF5OaZGuRJ9m4fTukYgmbk2pi7eb3YcERExUUJCAjabjdDQ0CLbQ0NDiY2NLdYxnn76aapWrVqksHW+KVOmEBAQULhERET8rdyl4uhqiNsFbt5nb3LiJGZucFy6N6xdDaxWNTgXEREBJyhKXWlPBAB/f39iYmIKl2PHjpViYinT6vcC3zDISID9P5udptgsFgvP9m0CwJzNx9lzsgx8Wi0iIk7ptddeY9asWcyfP/+yH+xNmDCB5OTkwiU6OroUU16ldR851pHDwfvSs8BK24G4VDYfO4OL1cJgNTgXEREpZHpR6kp7IoDjD/SwsLDC5fxPCkUuycUVWt3pGG8uO5fwAbSpWYm+LcIxDHh14V4MwzA7koiImKBKlSq4uLgQFxdXZHtcXBxhYWGXfe5bb73Fa6+9xuLFi2nRosVl9/Xw8MDf37/I4tROH4L9vzjGHf5pbpbzFMySurFRCCH+muEvIiJSwNSi1NX2REhLS6NmzZpERETQv39/du/eXRpxpbxolX8XvsMr4MxRU6NcqWd6N8LdxcrvBxNYuf+U2XFERMQE7u7utGnTpkiT8oKm5Z06dbrk89544w1eeuklfv31V9q2bVsaUUvX+k8AA+rdBMENzE5TKCvXxrwt+Q3OO6jBuYiIyLlczXzxy/VE2Ldv30Wf07BhQz7//HNatGhBcnIyb731Fp07/397dx4XVb3/cfx1ZoBhR0RBcMN9B0vR1FxKDZcovZbm1dK0+lXqzWtW2qKWaVZmXtO8LS5tZpt60a6aWlluV9NALfd9Q1xBQLaZ+f0xOjGCOzKg7+fjcR7nnO/ZPmcOypfPfL/f05w//viDChXyN4fOysoiKyvLuV4iBumUG6t0Fah6lyMp9fkDEDsWat7j7qiuSMXSvvRtEcmHv+xmzH+30LJGGTzMbm/wKCIiRWzIkCH06dOHxo0b06RJEyZOnEh6ejqPPvooAI888gjly5fnjTfeAODNN99kxIgRzJo1i8jISOfYU/7+/vj7+7vtPgrN2dPw++eO5WZPuzWUCy3anETK2RzKl/KhVY2y7g5HRIqY1WolJyfH3WGIFDpPT0/MZvN1n8etSalr0axZM5dvAZs3b06dOnX44IMPGD16dL7933jjDV599dWiDFFKgrYjIGkTnNgBsx50vJUvdiyUreXuyC5rwF3V+ea3A+xMTmP2ugP0vqOyu0MSEZEi1qNHD44dO8aIESNISkqiYcOGLFq0yPlF3/79+zGZ/vrSYurUqWRnZ/PAAw+4nGfkyJGMGjWqKEO/MX7/HHLSoWxtxxdPxcisc133ujeuiFkDnIvcMux2O0lJSZw+fdrdoYjcMKVKlaJcuXIYxrX/fnNrUup6xkQ4z9PTk9tuu42dO3cWuH348OEMGTLEuZ6amloy3h4jN1b52+EfG2D5W47m/juXwq6fIOYxaDOsWA2OeqEgH0+eaVuDUfP/5N0l27m/YQQB3sXnldciIlI0Bg4cyMCBAwvc9vPPP7us792798YH5C7W3HNd94A7noLrqBgXtl3H0li75yQmA7rHaIBzkVvJ+YRUaGgovr6+1/VHu0hxY7fbycjIcL6gLjw8/JrP5dakVN4xEbp06QL8NSbCxSpZF7JarWzatIlOnToVuN1isWCxWAorZLmZeAdB7Bho3A9+eBm2/RfWfgCbvoY2LzrKzcWzMWGvOyrz6ep97D6eztSfd/F8h9ruDklERMQ9tn0PKfvBpzRE9XB3NC5mn2sldVetUMKDfNwcjYgUFavV6kxIhYSEuDsckRvCx8fxey05OZnQ0NBr7srn9sFohgwZwkcffcQnn3zCli1beOqpp/KNiTB8+HDn/q+99ho//PADu3fvZsOGDfTu3Zt9+/bx2GOPuesWpKQLqQY9v4SH50LZOnD2FCx8Dv7dwtGCqhjyNJsY1tGRiJq2Yg+HTp91c0QiIiJusmaqY964H3gWn8TP0dRMvjs/wHkTDXAucis5P4aUr6+vmyMRubHO/4xfz7hpbk9K9ejRg/HjxzNixAgaNmxIQkJCvjERjhw54tz/1KlTPP7449SpU4dOnTqRmprKqlWrqFu3rrtuQW4W1e6GJ1dA53cc37Ye2wqfd4MvusPxHe6OLp/2dcNoWqU0Wbk23l5U8IsBREREbmqHNsD+1WDycHTBLwbsdjtfrdtPuwnLOZmeTflSPrSppQHORW5F6rInN7vC+Bk37Ha7vRBiKTFSU1MJCgoiJSWFwMBAd4cjxdXZU7D8bUd3Pluuo7Lb5Alo/Tz4BLs7OqdNB1OIm7wCgP8MaEF0xVLuDUhE5CakuoNDsfwcvnvc0e2+QXfo9pG7o2H/iQyGz93Iyp0nAIiqEMQ7D0ZTIyzAzZGJSFHKzMxkz549VKlSBW9vb3eH43aRkZEMHjyYwYMHuzsUKWSX+lm/0nqD21tKiRRLPsHQYSw8vQZqxDoSU2veh0m3w9qPHIOqFgMNKgTxt9vKAzDm+y3cYjlmERG5laUegT/mOJabPe3WUKw2O9NW7CF24i+s3HkCi4eJlzrVYc5TzZWQEpESwzCMS07X+rbWdevW8cQTTxRKjF9++SVms5kBAwYUyvnE/ZSUErmUMjWg19fQ+zvHa6bPnoT/DoUPWjre1lcMDI2thcXDxNq9J1n8x9HLHyAiInIzWPex40ujSs0g4ja3hbHj6Bke/PcqRi/4k7M5VppWKc3iwa14vFVVPMyqaotIyXHkyBHnNHHiRAIDA13Khg4d6tzXbreTm3tlX9SXLVu20MbXmjZtGs8//zxffvklmZmZhXLOa5Wdne3W698s9JtS5EpUbwdProRO4x2tqJL/hM+6wKyH4MQut4YWUcqHx1tWBWDcwi1k59rcGo+IiMgNl3MWfpvuWL7jKfeEYLXx3rIddJ60gg37T+Nv8WBM1/p8+fgdRJbxc0tMIiLXo1y5cs4pKCgIwzCc61u3biUgIICFCxfSqFEjLBYLK1asYNeuXdx///2EhYXh7+9PTEwMS5e6viwqMjKSiRMnOtcNw+Djjz+ma9eu+Pr6UqNGDeLj4y8b3549e1i1ahXDhg2jZs2azJkzJ98+06dPp169elgsFsLDwxk4cKBz2+nTp/m///s/wsLC8Pb2pn79+ixYsACAUaNG0bBhQ5dzTZw4kcjISOd637596dKlC2PGjCEiIoJatWoB8Nlnn9G4cWMCAgIoV64cf//730lOTnY51x9//MG9995LYGAgAQEBtGzZkl27dvHLL7/g6elJUlKSy/6DBw+mZcuWl/1MbgZKSolcKbMHNHkcBm2Apk+CYYbtC2FKU1j8EmSmuC20J9tUo4y/hb0nMnj+20R+339KXflEROTmtfErR+vloEpQq3ORX37TwRTi3lvBO0u2k221cXftUJYMaUWvppUxmTSwsYjkZ7fbycjOdctUmH8XDBs2jHHjxrFlyxaioqJIS0ujU6dOLFu2jN9//50OHToQFxfH/v37L3meV199le7du7Nx40Y6depEr169OHny5CWPmTFjBp07dyYoKIjevXszbdo0l+1Tp05lwIABPPHEE2zatIn4+HiqV68OgM1mo2PHjqxcuZLPP/+cP//8k3HjxmE2m6/q/pctW8a2bdtYsmSJM6GVk5PD6NGjSUxMZN68eezdu5e+ffs6jzl06BCtWrXCYrHw448/sn79evr160dubi6tWrWiatWqfPbZZ879c3Jy+OKLL+jXr99VxVZSebg7AJESx7c0dHzT8erpxS/CzqWwejIkzoa7X4Lb+4Dp6v5zu17+Fg+e71CL57/dyLyEw8xLOEzF0j7ERUUQFx1B7XIBevuHiIjcHOx2WDPVsdz0/xxfGhWRzBwr7y7dzke/7MZmh2BfT0bdV4/7oiP0e1ZELulsjpW6Ixa75dp/vhaLr1fh/F/52muv0b59e+d66dKliY6Odq6PHj2auXPnEh8f79JK6UJ9+/alZ8+eAIwdO5ZJkyaxdu1aOnToUOD+NpuNmTNn8t577wHw0EMP8eyzzzoH2QZ4/fXXefbZZ3nmmWecx8XExACwdOlS1q5dy5YtW6hZsyYAVatWver79/Pz4+OPP8bLy8tZljd5VLVqVSZNmkRMTAxpaWn4+/szZcoUgoKCmD17Np6engDOGAD69+/PjBkzeO655wCYP38+mZmZdO/e/arjK4nUUkrkWpWt5Rhrqte3UKYmZByHBf+ED1rB7uVFHk73xhX5pF8T7m8Yga+XmQMnz/L+z7vo+K9faf/uL0xatoM9x9OLPC4REZFCtfsnOLYVvPzh9oeL7LL/232Cjv/6lQ+WOxJScdERLB3SmvsblldCSkRuGY0bN3ZZT0tLY+jQodSpU4dSpUrh7+/Pli1bLttSKioqyrns5+dHYGBgvi5veS1ZsoT09HQ6deoEQJkyZWjfvj3Tpzu6cicnJ3P48GHatm1b4PEJCQlUqFDBJRl0LRo0aOCSkAJYv349cXFxVKpUiYCAAFq3bg3g/AwSEhJo2bKlMyF1ob59+7Jz507WrFkDwMyZM+nevTt+frdGV3C1lBK5XjXaQ9U2sG4a/DwWjm6GT++D2vfCPaOh9NVn4K9V65plaV2zLBnZufy4NZn5iYf5adsxdianMWHJdiYs2U798oHcFx1B56gIypfyKbLYRERECsXq9x3zhr3AO+iGX+5MZg5vLdrGZ2v2ARAWaOH1Lg1oXzfshl9bRG4ePp5m/nwt1m3XLiwXJkqGDh3KkiVLGD9+PNWrV8fHx4cHHnjgsoOAX5igMQwDm+3iY+NOmzaNkydP4uPz198vNpuNjRs38uqrr7qUF+Ry200mU75ujjk5Ofn2u/D+09PTiY2NJTY2li+++IKyZcuyf/9+YmNjnZ/B5a4dGhpKXFwcM2bMoEqVKixcuJCff/75ksfcTJSUEikMZk+440mI6g4/jXUMvrp1Aez4wTH+VKvnwDuwyMLx9fLg3qgI7o2KIDUzhx/+OMr8xMOs2HmczYdS2XwolbH/3UrjysHc1zCCjvXDKRtgKbL4RERErsmx7bBzCWA4uu7dYD9tS+alOZs4nOJ4w1PPJhUZ1rEOQT4Ff9stInIxhmEUWhe64mTlypX07duXrl27Ao6WU3v37i3Ua5w4cYL//Oc/zJ49m3r16jnLrVYrd955Jz/88AMdOnQgMjKSZcuWcdddd+U7R1RUFAcPHmT79u0FtpYqW7YsSUlJ2O12Z+vXhISEy8a2detWTpw4wbhx46hYsSIAv/32W75rf/LJJ+Tk5Fy0tdRjjz1Gz549qVChAtWqVaNFixaXvfbNQt33RAqTb2noPB6eWgnV7gZrNqyaBO/dDus/AZu1yEMK9PbkgUYV+KRfE9a+2JbXu9SnaZXSGAb8tu8UI/7zB03HLuXhaf/j63UHSMnI/42AiIhIsfC/fzvmtTpCSLUbdplT6dkM+SqBR2es43BKJpVK+zLrsaa88bcoJaRERPKoUaMGc+bMISEhgcTERP7+979fssXTtfjss88ICQmhe/fu1K9f3zlFR0fTqVMn54Dno0aN4p133mHSpEns2LGDDRs2OMegat26Na1ataJbt24sWbKEPXv2sHDhQhYtWgRAmzZtOHbsGG+99Ra7du1iypQpLFy48LKxVapUCS8vL9577z12795NfHw8o0ePdtln4MCBpKam8tBDD/Hbb7+xY8cOPvvsM7Zt2+bcJzY2lsDAQF5//XUeffTRwvroSgQlpURuhNA60HsO/P1rCKkO6cdg/j/gw9awd4Xbwgrxt9D7jsp89X/NWDXsbl7uXIfoiqWw2eHXHcd5/ruNNB6zhMc++Y3/JBwiPSvXbbGKiIi4yDgJiV86lu946oZcwm63s2DjYdpNWM6c3w9hMuCxO6uwaHBLmlcvc0OuKSJSkk2YMIHg4GCaN29OXFwcsbGx3H777YV6jenTp9O1a9cCx+/r1q0b8fHxHD9+nD59+jBx4kTef/996tWrx7333suOHTuc+3733XfExMTQs2dP6taty/PPP4/V6mg0UKdOHd5//32mTJlCdHQ0a9euZejQoZeNrWzZssycOZNvvvmGunXrMm7cOMaPH++yT0hICD/++CNpaWm0bt2aRo0a8dFHH7m0mjKZTPTt2xer1cojjzxyrR9ViWTYb7H3xqemphIUFERKSgqBgUXXnUpuYbnZsO4j+PlNyEpxlNW5zzHeVHCkW0M7b9+JdBZsPML8xMNsTTrjLPfxNNO2Tihx0RG0rlkW70Lsjy4iUlKo7uDg9s9hxbuwdBSE1YcnV0AhDy6enJrJy/M288OfRwGoEerPWw9EcVul4EK9jojc/DIzM51vhfP29nZ3OFJC9O/fn2PHjhEfH+/uUK7YpX7Wr7TecPN1ahUpbjy8oNkAiHoIfhoD62fAlnjYvshR3vJZsAS4NcTKIX4MuKs6A+6qzvajZ5ifeJj4xMPsO5HBgo1HWLDxCAEWD2LrlyMuOoIW1ULwMKuhpYiIFBFrDqz9yLF8x1OFmpCy2+1889tBRn//J2cyc/EwGTx9V3UG3FUNi4e+jBERkRsrJSWFTZs2MWvWrBKVkCosSkqJFBW/ELh3AsT0h0XDYc9yx7e+v38BbUc43iJkcn+ip2ZYAM/eU4sh7Wuy6VAK8xMPMz/xCEmpmXy7/iDfrj9IaT8vOjUoR1xUBDGRpTGZ9CpsERG5gbbEQ+oh8CsL9R8otNMeOJnB8DmbWLHzOABRFYJ4s1sUdcJv3RZxIiJStO6//37Wrl3Lk08+Sfv27d0dTpFTUkqkqIXVg0f+A9sWwg8vwcndED/Q0cWvwzio3NzdEQKON4REVShFVIVSDO9Yh9/2nSI+8RD/3ZTEyfRsPl+zn8/X7KdcoDf3RoUTFx1BVIWgAvt6i4iIXJc1Ux3zxv3B8/q7wlhtdj5ZtZe3F2/jbI4Vi4eJZ++pSb8WVdQSWEREitTPP//s7hDcSkkpEXcwDKjdCaq3hbUfwvK34EgizOgIdbtA+9cguLK7o3QymQyaVClNkyqlGRVXj1W7ThCfeJjFm5NISs3k4xV7+HjFHiqH+BIXFUFcdAS1yrm3S6KIiNwkDqyDg+vA7OVobXyddiaf4flvN7Jh/2kAmlYpzZvdoogs43fd5xYREZGro6SUiDt5WKD5oHPjTb0OGz6FP+c5WlE1Hwh3DgGLv7ujdOFhNtGqZlla1SzL613q88v2Y8QnHmbplqPsO5HB5J92MvmnndQKCyAu2tGCqnKIKvoiInKN1rzvmDd4EPxDr/k0OVYbHyzfxaRlO8m22vC3eDC8U216xlRSN3QRERE3UVJKpDjwLwtx/4KYxxzjTe39FX59xzHeVLuRjqRVMRhv6kLenmbuqVeOe+qVIz0rl6VbjjI/8QjLtyez7egZtv1whvE/bCe6QhBx0RF0jgonPMjH3WGLiEhJkXIQ/vyPY7npk9d8mk0HU3ju20TnG2bvrh3KmK719TtJRETEzZSUEilOyjWAPvNh6wL44WU4tRfmPeXo4tdhHFS6w90RXpSfxYP7G5bn/oblScnIYfEfSczfeJiVO4+TeDCFxIMpjPnvFmIiSxMXHUGn+uUI8be4O2wRESnO1n4IditEtoTwqKs+PDPHysSlO/jo191YbXaCfT0ZdV897ouO0BiIIiIixYCSUiLFjWFAnTiocY9jYNdfxsPh32F6LNTvBu1ehVIV3R3lJQX5etI9piLdYypy7EwWCzcfYX7iYdbtPcXaPSdZu+cko+L/oEX1MsRFhRNbvxyB3p7uDltERIqT7HRYP9OxfMdTV3342j0nGfbdRnYfTwcgLjqCkXF1KaMvRERERIoNJaVEiisPC9w5GBr+HX4cDRs+g83fwdbvofk/HNu8iv9YTWUDLDzSLJJHmkVy6PRZvt94mPmJR9h0KIVfth/jl+3HeGnuZtrUKktcdATt6oTh42V2d9giIuJuiV9CZgoEV4GaHa74sLSsXN5cuJXP1uwDICzQwutdGtC+btiNilRERESuUfEbpEZEXPmHwn3vwf8th8otIDcTfnkL3msMiV+BzebuCK9Y+VI+PNGqGvMH3cmPz7ZmSPuaVA/1J9tq44c/jzLoy99p9PoS/vHl7yz58yhZuVZ3hywiIu5gs8GafzuWmz4Jpiv7suKnbcncM2G5MyHVs0lFfvhnayWkRESKUJs2bRg8eLBzPTIykokTJ17yGMMwmDdv3nVfu7DOI0VHLaVESorwaOj7PWyJd4w3dXo/zH3ir/GmKsa4O8KrUrWsP/9oW4NBd1dna9IZ5iceZv7Gwxw4eZb4xMPEJx4m0NuDDvXL0bhyacoGWijrbyE00EKInwWz3pQkInLz2rkUTuwASyDc1uuyu59Kz2b0gj+Z8/shACqV9mXc3xrQvHqZGx2piMhNIy4ujpycHBYtWpRv26+//kqrVq1ITEwkKurqxvhbt24dfn6F28Nj1KhRzJs3j4SEBJfyI0eOEBwcXKjXupizZ89Svnx5TCYThw4dwmJR9/BroaSUSEliGFD3fqgRC2umwK8T4NBvMK2d41XZ7UZBUAV3R3lVDMOgTnggdcIDeS62FgkHTjM/8QgLNh4m+UwWX/92kK9/O+hyjNlkEOLnRWighdAAb0IDLIQGWCgb6O1MXIUGWCgbYMHioa6AIiIlzpr3HfPbHgZLwEV3s9vt/HdTEiPjN3M8LRvDgH4tqvDsPTXx9VI1V0TkavTv359u3bpx8OBBKlRw/ZtixowZNG7c+KoTUgBly5YtrBAvq1y5ckV2re+++4569epht9uZN28ePXr0KLJrX8hut2O1WvHwKHm/+9R9T6Qk8vSGls/CoPXQsDdgwKZvHF36pneE2b0gfhAsHQWr3oPfv4Bti+DAOjixC86eKpbd/gzD4LZKwYyIq8vq4W358vE76NOsMq1rlqVOeCBl/C0YBlhtdpLPZLH5UCo/bk1m9roDTPpxJ6/M28yTn6/nb++v4s43f6LWy4to+NoP3PPucnp//D+GfJXAGwu38PGvu4lPPMya3SfYfSyNtKzcorlBux2yzjhecZ5xsmiuKSJS0iRvgd0/gWGCpk9cfLfUTJ78fD0DZm3geFo2NUL9+e6p5rxyb10lpERErsG9995L2bJlmTlzpkt5Wloa33zzDf379+fEiRP07NmT8uXL4+vrS4MGDfjyyy8ved4Lu+/t2LGDVq1a4e3tTd26dVmyZEm+Y1544QVq1qyJr68vVatW5ZVXXiEnJweAmTNn8uqrr5KYmIhhGBiG4Yz5wu57mzZt4u6778bHx4eQkBCeeOIJ0tLSnNv79u1Lly5dGD9+POHh4YSEhDBgwADntS5l2rRp9O7dm969ezNt2rR82//44w/uvfdeAgMDCQgIoGXLluzatcu5ffr06dSrVw+LxUJ4eDgDBw4EYO/evRiG4dIK7PTp0xiGwc8//wzAzz//jGEYLFy4kEaNGmGxWFixYgW7du3i/vvvJywsDH9/f2JiYli6dKlLXFlZWbzwwgtUrFgRi8VC9erVmTZtGna7nerVqzN+/HiX/RMSEjAMg507d172M7kW+o0tUpIFlIMuU6DJY7BoOOxfDftXXdmxhhl8S4NPafANcSy7zEPyb/MOcrTWKgJmk0GzaiE0qxbiUp5rtXEiPZvk1CySz2SSfCbLZfnYuSn5TCY5VjunM3I4nZHD9qNpF7mSg6+X+VyLK2+XroLOlljnloMtdozMVMfgu5mnHdPZ03nWU/Kv5y2z5xknyycYQmpASHUoU90xD6kBpas6Eo8iIreiNVMd89qdITgy32a73c436w/y+oI/Sc3MxcNk8PRd1RlwVzW1jhWR4stuh5wM91zb0/eK6vAeHh488sgjzJw5k5deegnj3DHffPMNVquVnj17kpaWRqNGjXjhhRcIDAzk+++/5+GHH6ZatWo0adLkstew2Wz87W9/IywsjP/973+kpKS4jD91XkBAADNnziQiIoJNmzbx+OOPExAQwPPPP0+PHj3YvHkzixYtciZcgoKC8p0jPT2d2NhYmjVrxrp160hOTuaxxx5j4MCBLom3n376ifDwcH766Sd27txJjx49aNiwIY8//vhF72PXrl2sXr2aOXPmYLfb+ec//8m+ffuoXLkyAIcOHaJVq1a0adOGH3/8kcDAQFauXEluruPL8KlTpzJkyBDGjRtHx44dSUlJYeXKlZf9/C40bNgwxo8fT9WqVQkODubAgQN06tSJMWPGYLFY+PTTT4mLi2Pbtm1UqlQJgEceeYTVq1czadIkoqOj2bNnD8ePH8cwDPr168eMGTMYOnSo8xozZsygVatWVK9e/arjuxJKSoncDCJug0cXwqH1kHIAMk5Axqlz83PT2ZPnlk9CdpojOZJ+zDFdqfOJLGfCKk8CK18y68YksjzMJsICvQkL9Aby//I5z253JKSSzyWoHImrLJJTMziTcoqM1JNkp50kN/0UltwzBFrTCTydTmBKBoFkEGSkE0j6ublj3ZsMDCPr+m/C5Am2HEeLtYNrHZMLA0pVPJekOpeoCqkGZWpAYAUwqZGriNyk0k/Axq8cy3c8nW/zgZMZDJ+ziRU7jwMQVSGIN7tFUSc8sCijFBG5ejkZMDbCPdd+8fAVv7W7X79+vP322yxfvpw2bdoAjqREt27dCAoKIigoyCVhMWjQIBYvXszXX399RUmppUuXsnXrVhYvXkxEhOPzGDt2LB07dnTZ7+WXX3YuR0ZGMnToUGbPns3zzz+Pj48P/v7+eHh4XLK73qxZs8jMzOTTTz91jmk1efJk4uLiePPNNwkLc7wEIzg4mMmTJ2M2m6lduzadO3dm2bJll0xKTZ8+nY4dOzrHr4qNjWXGjBmMGjUKgClTphAUFMTs2bPx9PQEoGbNms7jX3/9dZ599lmeeeYZZ1lMzNWPEfzaa6/Rvn1753rp0qWJjo52ro8ePZq5c+cSHx/PwIED2b59O19//TVLliyhXbt2AFStWtW5f9++fRkxYgRr166lSZMm5OTkMGvWrHytpwqTklIiNwvDgAqNHdPl5GY5klMFJaxc5ueWz15HIsvk4WgR5ExY5VnOl8wKvrJEVk7mJVomOZaNs6cJzkwhOPM0tfLuk5UK9jxdF02A15Xfznmpdl9S8SXV7keK3Y9UfF3mZ/DDagnC8AnC07803v6l8QsqTUCpMoSUKkUpz1wCM/bjn7YX3zN78E7djSVlD56nd2HKSnUMZH96P+z60fXCHt5QutpfSaq8SSvf0ld/IyIixcn66Y63zIZHQ6VmzmKrzc6nq/fy1qJtnM2xYvEw8ew9NenXogoeZiXqRUQKS+3atWnevDnTp0+nTZs27Ny5k19//ZXXXnsNAKvVytixY/n66685dOgQ2dnZZGVl4evre0Xn37JlCxUrVnQmpACaNWuWb7+vvvqKSZMmsWvXLtLS0sjNzSUw8Oq+gNiyZQvR0dEug6y3aNECm83Gtm3bnEmpevXqYTb/1dI2PDycTZs2XfS8VquVTz75hH/961/Ost69ezN06FBGjBiByWQiISGBli1bOhNSeSUnJ3P48GHatm17VfdTkMaNXf/2S0tLY9SoUXz//fccOXKE3Nxczp49y/79+wFHVzyz2Uzr1q0LPF9ERASdO3dm+vTpNGnShPnz55OVlcWDDz543bFejJJSIrciDwsEhjumK5WTWUDy6oSjtU/eFlkZJ//anpMOttxrTGSV/qt7oS3XNQmVm3nVt5yP2QI+pRwJMO/z86D8ZXnWsz0DOW714WimJ8npuee6CWZxLG9LrDOZHE/LxmqzQwaO6cT5i545N+UVfG66/dy6nRBSqWocoYrpCNWMI1QzJVHVOEJF4yieuZmQ/IdjusAZUyDJXhU5bqnICUslTvlU5rRvZdL9KmL28sHLbMLLI89kvmB+wbLFw4SX2YyXhwlPs+Gyj1FE3Til5Mu12sjKdUzZuTaycq2O9RzHcnbu+e15yq02snKszuNc9sv5a9+857u7ViiD2tZw9+3K9cjNhrUfO5bvGOD8cmJn8hle+G4T6/edAqBJldK82S2KKmUK901OIiI3lKevo8WSu659Ffr378+gQYOYMmUKM2bMoFq1as4kxttvv82//vUvJk6cSIMGDfDz82Pw4MFkZ2cXWrirV6+mV69evPrqq8TGxjpbHL3zzjuFdo28LkwcGYaB7RLj7y5evJhDhw7lG9jcarWybNky2rdvj4+Pz0WPv9Q2ANO5XhF2u91ZdrExri58q+HQoUNZsmQJ48ePp3r16vj4+PDAAw84n8/lrg3w2GOP8fDDD/Puu+8yY8YMevToccVJx2uhpJSIXBlPb/CMgMCraHbsksgqIGmVr5XWyTyJrGTHdFEGeAcWmDxyzi+RYLqWMZu8gIhz06VYbXZOpmeTfCYzT+Iqi+TUc2NgnckiLTOXbKvN+Yd2dq6VHKudbKuNE7YgTtiDWGet7XJeM1bKG8epahymqpFEVeMwVYwkqpqOEG6cJMCWSkDmH1TLdE1Y2ewGB+1l2GMPZ3eeaY8tnCOUxn4N77woKJFl8TDh62XG29OMr5cZXy8PfLwcyz5eZnw8zy974Ot5Yflf+54/h8VDya/rdT4hlF1QUij3wuSOayKooATSRRNL1vPL+c9ptdkvH2ghUILiJvDHXEhLAv8wqNeVHKuND5bvYtKynWRbbfhbPBjWsTZ/b1IJk0n/N4hICWMYV9yFzt26d+/OM888w6xZs/j000956qmnnHWylStXcv/999O7d2/AMUbU9u3bqVu37hWdu06dOhw4cIAjR44QHu74gnzNmjUu+6xatYrKlSvz0ksvOcv27dvnso+XlxdWq5VLqVOnDjNnziQ9Pd2ZvFm5ciUmk4latWpdUbwFmTZtGg899JBLfABjxoxh2rRptG/fnqioKD755BNycnLyJb0CAgKIjIxk2bJl3HXXXfnOf/5thUeOHOG2224DcBn0/FJWrlxJ37596dq1K+BoObV3717n9gYNGmCz2Vi+fLmz+96FOnXqhJ+fH1OnTmXRokX88ssvV3Tta6WklIjcONeUyDr7V9LqfMLK5Jk/wWQJLLZjK5lNBmUDLJQNsFzT8Vabnezzf9Rbrc7lbKuNnFw72da//uhPz7Wx3mrDmnkGS4qjK6DfmT0EpO8jMGMvwWf3Y7GmU8k4RiWO0ZqNLtfKMiwcMUdwyBTBfqM8ewlnDxHsspbjhM3Xee3cCxIL2VZHPBTCEFsXYzYZ+Hia/0psuSx7OBNY+RJeeRJbvgXs7+1lxtfTfMO6/NjtdnLPPcO8SZy/WgS5rl9sv4LXL3b8X4mhvPOiSghdKU+z4Uhemm34e9jw97DiZ7bh52HD12TF15yLr9mGj8mKj8mKtynXMTdy8TblYjFy8TKsWMjBi1y8jFy8yMHTnoNHeCOgobtvUa6V3Q5rpjiWYx5n89GzPPftRrYcSQXgrlplGdO1ARGlLv8Nr4iIXB9/f3969OjB8OHDSU1NpW/fvs5tNWrU4Ntvv2XVqlUEBwczYcIEjh49esVJqXbt2lGzZk369OnD22+/TWpqar7kTo0aNdi/fz+zZ88mJiaG77//nrlz57rsExkZyZ49e0hISKBChQoEBARgsbjWvXv16sXIkSPp06cPo0aN4tixYwwaNIiHH37Y2XXvah07doz58+cTHx9P/fr1XbY98sgjdO3alZMnTzJw4EDee+89HnroIYYPH05QUBBr1qyhSZMm1KpVi1GjRvHkk08SGhpKx44dOXPmDCtXrmTQoEH4+Phwxx13MG7cOKpUqUJycrLLGFuXUqNGDebMmUNcXByGYfDKK6+4tPqKjIykT58+9OvXzznQ+b59+0hOTqZ79+4AmM1m+vbty/Dhw6lRo0aB3SsLk5JSIlK8ePpAUHnHdIsymwxHosXLDOTvh35xBXzjY7c7uk4e3wEndsKJHXBil2P91B4stiwic/cQyR5aXHisbxnnmwFtpauTW6oqWaWqkelfiRzD05koy9vK5myOlYxsK2ezrWRk55KRYyUz21GWkZOnPNtKpsu+jvKzOY4WY+BIzqVl5ZKWlXuNn+SleZlNl23J5Wk25bnHC1sROVq4XdiyKDvXRtHlguyYsZ2brJixYcKGNzb8sGPChgdWTIYNi2HH4gHeZjv+Zhu+ZqvL5EwCGbl4m2x4G7lYTDlYsJ5LBuU6EkHk4EEunvYcPMnBw56Lhz0Hsz0bsz0Xsy0bsy0bky0Hw5aNyZqDYc0Ga/a5eRbYgOxzU2HxzQJ6F+IJpUjtXwNHErF7eDMp5U4mTVmJ1WYn2NeTkXH1uL9hhFpOiogUof79+zNt2jQ6derkMv7Tyy+/zO7du4mNjcXX15cnnniCLl26kJKSckXnNZlMzJ07l/79+9OkSRMiIyOZNGkSHTp0cO5z33338c9//pOBAweSlZVF586deeWVV5yDiAN069aNOXPmcNddd3H69GlmzJjhkjwD8PX1ZfHixTzzzDPExMTg6+tLt27dmDBhwjV/LucHTS9oPKi2bdvi4+PD559/zj/+8Q9+/PFHnnvuOVq3bo3ZbKZhw4a0aOGocffp04fMzEzeffddhg4dSpkyZXjggQec55o+fTr9+/enUaNG1KpVi7feeot77rnnsvFNmDCBfv360bx5c8qUKcMLL7xAamqqyz5Tp07lxRdf5Omnn+bEiRNUqlSJF1980WWf/v37M3bsWB599NFr+ZiuimHP21HxFpCamkpQUBApKSlXPVCaiMhNxZoLp/c5klXOpNW56cyRix9nmKBUpfxvBvQvB9gdA8nbz89tF5QVVO66f67NRnZOLlk5uWTlWMnOySE7x0q21Up2Tq5jynUs5+RaybG6LufkOpZzrVZyc60uy7k2K4bdjoFjMmHDAEzYMZzLNse64djuSPj8tXw+0XN+2YwNk+GYe+QtOzf3MGx4GjY8DDseeeZm7HgY1nP75L2WI8FkOncOk/2vuYEVk92KYbdh2K0Y3AS/wg0zmL3Aw8sx1pvLsqdjDDyz17nyc2VmywXLXhBxO9T/2w0JUXUHhxv6Oaz/BOt/n2eR0ZIBaY4KcFx0BCPj6lLG/9panYqIuEtmZiZ79uyhSpUqeHtf/ZARIu7266+/0rZtWw4cOHDJVmWX+lm/0nqDWkqJiNyqzB6OhFJINagZ67ot64yjRVXeRNXxc62sss/Aqb2OaefSQg/L49xU6MMpms5N7mQ/NxUVw+x4cYDJfG7Z5JjnS/R4XUFiKO9yQYmhC5JEZq8Llgu6nsURm9zypp1txaT0SXiRQ2iAhTFdG9C+7rV1rRAREZFrk5WVxbFjxxg1ahQPPvjgNXdzvBpKSomISH6WAIho6Jjystsh7egFrat2OboFZpxwtKLCcMwNk2NQz7zLF9vmUk6e5UucDy5ynbzHGJe4zhXGZpjPJXVMjrnJI3+ZS/Inb1nebaYLyswF7HeZbQXub7og8ZQnASVSQtxZvQxvmgPpeHt5hneqQ5DP1XRdFhERkcLw5Zdf0r9/fxo2bMinn35aJNdUUkpERK6cYUBAOccUeae7oxGRm0StcgH8OLQ1FYJv3CunRURE5NL69u2bb2yuG01fo4qIiIiI2ykhJSIicutRUkpERERERERERIpcsUhKTZkyhcjISLy9vWnatClr16695P7ffPMNtWvXxtvbmwYNGvDf//63iCIVERERERERubxb7EX3cgsqjJ9xtyelvvrqK4YMGcLIkSPZsGED0dHRxMbGkpycXOD+q1atomfPnvTv35/ff/+dLl260KVLFzZv3lzEkYuIiIiIiIi48vR0vKwhIyPDzZGI3Fjnf8bP/8xfC8Pu5vRt06ZNiYmJYfLkyQDYbDYqVqzIoEGDGDZsWL79e/ToQXp6OgsWLHCW3XHHHTRs2JB///vfl71eamoqQUFBpKSkEBgYWHg3IiIiIjcl1R0c9DmIiFy5I0eOcPr0aUJDQ/H19cUwDHeHJFJo7HY7GRkZJCcnU6pUKcLDw/Ptc6X1Bre+fS87O5v169czfPhwZ5nJZKJdu3asXr26wGNWr17NkCFDXMpiY2OZN2/ejQxVRERERERE5IqUK1cO4KI9gERuBqVKlXL+rF8rtyaljh8/jtVqJSwszKU8LCyMrVu3FnhMUlJSgfsnJSUVuH9WVhZZWVnO9dTU1OuMWkREREREROTiDMMgPDyc0NBQcnJy3B2OSKHz9PTEbDZf93ncmpQqCm+88Qavvvqqu8MQERERERGRW4zZbC6UP9xFblZuHei8TJkymM1mjh496lJ+9OjRizYBK1eu3FXtP3z4cFJSUpzTgQMHCid4ERERERERERG5Zm5NSnl5edGoUSOWLVvmLLPZbCxbtoxmzZoVeEyzZs1c9gdYsmTJRfe3WCwEBga6TCIiIiIiIiIi4l5u7743ZMgQ+vTpQ+PGjWnSpAkTJ04kPT2dRx99FIBHHnmE8uXL88YbbwDwzDPP0Lp1a9555x06d+7M7Nmz+e233/jwww/deRsiIiIiIiIiInIV3J6U6tGjB8eOHWPEiBEkJSXRsGFDFi1a5BzMfP/+/ZhMfzXoat68ObNmzeLll1/mxRdfpEaNGsybN4/69etf0fXsdjugAc9FRETkypyvM5yvQ9yqVIcSERGRK3Wl9SfDfovVsA4ePEjFihXdHYaIiIiUMAcOHKBChQruDsNtVIcSERGRq3W5+tMtl5Sy2WwcPnyYgIAADMMo9POnpqZSsWJFDhw4oPGrijk9q5JBz6lk0HMqGfScro3dbufMmTNERES4tN6+1agOJaDnVFLoOZUcelYlg57T1bvS+pPbu+8VNZPJVCTfcmpQ9ZJDz6pk0HMqGfScSgY9p6sXFBTk7hDcTnUoyUvPqWTQcyo59KxKBj2nq3Ml9adb9+s+ERERERERERFxGyWlRERERERERESkyCkpVcgsFgsjR47EYrG4OxS5DD2rkkHPqWTQcyoZ9JykONPPZ8mg51Qy6DmVHHpWJYOe041zyw10LiIiIiIiIiIi7qeWUiIiIiIiIiIiUuSUlBIRERERERERkSKnpJSIiIiIiIiIiBQ5JaUK2ZQpU4iMjMTb25umTZuydu1ad4ckebzxxhvExMQQEBBAaGgoXbp0Ydu2be4OSy5j3LhxGIbB4MGD3R2KFODQoUP07t2bkJAQfHx8aNCgAb/99pu7w5I8rFYrr7zyClWqVMHHx4dq1aoxevRoNKykFBeqPxV/qkOVTKpDFV+qPxV/qj8VDSWlCtFXX33FkCFDGDlyJBs2bCA6OprY2FiSk5PdHZqcs3z5cgYMGMCaNWtYsmQJOTk53HPPPaSnp7s7NLmIdevW8cEHHxAVFeXuUKQAp06dokWLFnh6erJw4UL+/PNP3nnnHYKDg90dmuTx5ptvMnXqVCZPnsyWLVt48803eeutt3jvvffcHZqI6k8lhOpQJY/qUMWX6k8lg+pPRUNv3ytETZs2JSYmhsmTJwNgs9moWLEigwYNYtiwYW6OTgpy7NgxQkNDWb58Oa1atXJ3OHKBtLQ0br/9dt5//31ef/11GjZsyMSJE90dluQxbNgwVq5cya+//uruUOQS7r33XsLCwpg2bZqzrFu3bvj4+PD555+7MTIR1Z9KKtWhijfVoYo31Z9KBtWfioZaShWS7Oxs1q9fT7t27ZxlJpOJdu3asXr1ajdGJpeSkpICQOnSpd0ciRRkwIABdO7c2eXflRQv8fHxNG7cmAcffJDQ0FBuu+02PvroI3eHJRdo3rw5y5YtY/v27QAkJiayYsUKOnbs6ObI5Fan+lPJpTpU8aY6VPGm+lPJoPpT0fBwdwA3i+PHj2O1WgkLC3MpDwsLY+vWrW6KSi7FZrMxePBgWrRoQf369d0djlxg9uzZbNiwgXXr1rk7FLmE3bt3M3XqVIYMGcKLL77IunXr+Mc//oGXlxd9+vRxd3hyzrBhw0hNTaV27dqYzWasVitjxoyhV69e7g5NbnGqP5VMqkMVb6pDFX+qP5UMqj8VDSWl5JY1YMAANm/ezIoVK9wdilzgwIEDPPPMMyxZsgRvb293hyOXYLPZaNy4MWPHjgXgtttuY/Pmzfz73/9WpaoY+frrr/niiy+YNWsW9erVIyEhgcGDBxMREaHnJCJXTXWo4kt1qJJB9aeSQfWnoqGkVCEpU6YMZrOZo0ePupQfPXqUcuXKuSkquZiBAweyYMECfvnlFypUqODucOQC69evJzk5mdtvv91ZZrVa+eWXX5g8eTJZWVmYzWY3RijnhYeHU7duXZeyOnXq8N1337kpIinIc889x7Bhw3jooYcAaNCgAfv27eONN95QpUrcSvWnkkd1qOJNdaiSQfWnkkH1p6KhMaUKiZeXF40aNWLZsmXOMpvNxrJly2jWrJkbI5O87HY7AwcOZO7cufz4449UqVLF3SFJAdq2bcumTZtISEhwTo0bN6ZXr14kJCSoMlWMtGjRIt8rwbdv307lypXdFJEUJCMjA5PJ9Ve+2WzGZrO5KSIRB9WfSg7VoUoG1aFKBtWfSgbVn4qGWkoVoiFDhtCnTx8aN25MkyZNmDhxIunp6Tz66KPuDk3OGTBgALNmzeI///kPAQEBJCUlARAUFISPj4+bo5PzAgIC8o1R4efnR0hIiMauKGb++c9/0rx5c8aOHUv37t1Zu3YtH374IR9++KG7Q5M84uLiGDNmDJUqVaJevXr8/vvvTJgwgX79+rk7NBHVn0oI1aFKBtWhSgbVn0oG1Z+KhmG32+3uDuJmMnnyZN5++22SkpJo2LAhkyZNomnTpu4OS84xDKPA8hkzZtC3b9+iDUauSps2bfQ642JqwYIFDB8+nB07dlClShWGDBnC448/7u6wJI8zZ87wyiuvMHfuXJKTk4mIiKBnz56MGDECLy8vd4cnovpTCaA6VMmlOlTxpPpT8af6U9FQUkpERERERERERIqcxpQSEREREREREZEip6SUiIiIiIiIiIgUOSWlRERERERERESkyCkpJSIiIiIiIiIiRU5JKRERERERERERKXJKSomIiIiIiIiISJFTUkpERERERERERIqcklIiIiIiIiIiIlLklJQSEblOhmEwb948d4chIiIiUmKo/iQioKSUiJRwffv2xTCMfFOHDh3cHZqIiIhIsaT6k4gUFx7uDkBE5Hp16NCBGTNmuJRZLBY3RSMiIiJS/Kn+JCLFgVpKiUiJZ7FYKFeunMsUHBwMOJqGT506lY4dO+Lj40PVqlX59ttvXY7ftGkTd999Nz4+PoSEhPDEE0+Qlpbmss/06dOpV68eFouF8PBwBg4c6LL9+PHjdO3aFV9fX2rUqEF8fPyNvWkRERGR66D6k4gUB0pKichN75VXXqFbt24kJibSq1cvHnroIbZs2QJAeno6sbGxBAcHs27dOr755huWLl3qUmmaOnUqAwYM4IknnmDTpk3Ex8dTvXp1l2u8+uqrdO/enY0bN9KpUyd69erFyZMni/Q+RURERAqL6k8iUiTsIiIlWJ8+fexms9nu5+fnMo0ZM8Zut9vtgP3JJ590OaZp06b2p556ym632+0ffvihPTg42J6Wlubc/v3339tNJpM9KSnJbrfb7REREfaXXnrpojEA9pdfftm5npaWZgfsCxcuLLT7FBERESksqj+JSHGhMaVEpMS76667mDp1qktZ6dKlncvNmjVz2dasWTMSEhIA2LJlC9HR0fj5+Tm3t2jRApvNxrZt2zAMg8OHD9O2bdtLxhAVFeVc9vPzIzAwkOTk5Gu9JREREZEbSvUnESkOlJQSkRLPz88vX3PwwuLj43NF+3l6erqsG4aBzWa7ESGJiIiIXDfVn0SkONCYUiJy01uzZk2+9Tp16gBQp04dEhMTSU9Pd25fuXIlJpOJWrVqERAQQGRkJMuWLSvSmEVERETcSfUnESkKaiklIiVeVlYWSUlJLmUeHh6UKVMGgG+++YbGjRtz55138sUXX7B27VqmTZsGQK9evRg5ciR9+vRh1KhRHDt2jEGDBvHwww8TFhYGwKhRo3jyyScJDQ2lY8eOnDlzhpUrVzJo0KCivVERERGRQqL6k4gUB0pKiUiJt2jRIsLDw13KatWqxdatWwHHm11mz57N008/TXh4OF9++SV169YFwNfXl8WLF/PMM88QExODr68v3bp1Y8KECc5z9enTh8zMTN59912GDh1KmTJleOCBB4ruBkVEREQKmepPIlIcGHa73e7uIEREbhTDMJg7dy5dunRxdygiIiIiJYLqTyJSVDSmlIiIiIiIiIiIFDklpUREREREREREpMip+56IiIiIiIiIiBQ5tZQSEREREREREZEip6SUiIiIiIiIiIgUOSWlRERERERERESkyCkpJSIiIiIiIiIiRU5JKRERERERERERKXJKSomIiIiIiIiISJFTUkpERERERERERIqcklIiIiIiIiIiIlLklJQSEREREREREZEi9/+tVHXt7mtuxgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence, to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv3D, MaxPooling3D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class VideoDataGenerator(Sequence):\n",
    "    def __init__(self, data_dir, target_size, batch_size=32, frames_per_clip=15, desired_classes=None):\n",
    "        \"\"\"\n",
    "        Initialize the VideoDataGenerator.\n",
    "\n",
    "        Args:\n",
    "            data_dir: Path to the directory containing the data.\n",
    "            target_size: Tuple (height, width) for resizing frames.\n",
    "            batch_size: Number of samples per batch.\n",
    "            frames_per_clip: Number of frames in each video clip.\n",
    "            desired_classes: List of class names to include (default is None, which includes all classes).\n",
    "        \"\"\"\n",
    "        self.data_dir = data_dir\n",
    "        self.target_size = target_size\n",
    "        self.batch_size = batch_size\n",
    "        self.frames_per_clip = frames_per_clip\n",
    "\n",
    "        # Filter and sort the classes as per the desired_classes\n",
    "        if desired_classes:\n",
    "            self.classes = sorted([cls for cls in desired_classes if cls in os.listdir(data_dir)])\n",
    "        else:\n",
    "            self.classes = sorted(os.listdir(data_dir))\n",
    "\n",
    "        # Create a dictionary mapping class names to indices\n",
    "        self.class_indices = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "        \n",
    "        # Load clips and labels\n",
    "        self.clip_files, self.labels = self._load_clips_and_labels()\n",
    "\n",
    "    def _load_clips_and_labels(self):\n",
    "        \"\"\"\n",
    "        Load clip file paths and corresponding labels from the data directory.\n",
    "\n",
    "        Returns:\n",
    "            clip_files: List of clip file paths.\n",
    "            labels: List of labels corresponding to the clips.\n",
    "        \"\"\"\n",
    "        clip_files = []\n",
    "        labels = []\n",
    "\n",
    "        # Iterate through each class\n",
    "        for cls in self.classes:\n",
    "            class_dir = os.path.join(self.data_dir, cls)\n",
    "            \n",
    "            # Check if the directory exists\n",
    "            if not os.path.exists(class_dir):\n",
    "                print(f\"Class directory '{class_dir}' does not exist.\")\n",
    "                continue\n",
    "            \n",
    "            # Iterate through each video directory within the class directory\n",
    "            video_dirs = [os.path.join(class_dir, vid) for vid in os.listdir(class_dir) if os.path.isdir(os.path.join(class_dir, vid))]\n",
    "\n",
    "            print(f\"Processing class '{cls}' with {len(video_dirs)} video directories.\")\n",
    "\n",
    "            # Process each video directory\n",
    "            for vid_dir in video_dirs:\n",
    "                # List frames in the video directory\n",
    "                frames = sorted(os.listdir(vid_dir))\n",
    "                num_frames = len(frames)\n",
    "\n",
    "                # Create clips from frames\n",
    "                for i in range(0, num_frames - self.frames_per_clip + 1, self.frames_per_clip):\n",
    "                    clip_files.append([os.path.join(vid_dir, frames[j]) for j in range(i, i + self.frames_per_clip)])\n",
    "                    labels.append(self.class_indices[cls])\n",
    "\n",
    "        print(f\"Loaded {len(clip_files)} clips with labels.\")\n",
    "        return clip_files, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        Returns the number of batches in the dataset.\n",
    "        \"\"\"\n",
    "        return len(self.clip_files) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Generate one batch of data.\n",
    "\n",
    "        Args:\n",
    "            index: Batch index.\n",
    "\n",
    "        Returns:\n",
    "            batch_clips: Batch of clips as a numpy array.\n",
    "            batch_labels: One-hot encoded labels as a numpy array.\n",
    "        \"\"\"\n",
    "        start_index = index * self.batch_size\n",
    "        end_index = start_index + self.batch_size\n",
    "\n",
    "        # Get the clip files and labels for the current batch\n",
    "        batch_files = self.clip_files[start_index:end_index]\n",
    "        batch_labels = self.labels[start_index:end_index]\n",
    "\n",
    "        # Load clips and process them\n",
    "        batch_clips = []\n",
    "        for clip_files in batch_files:\n",
    "            clip = [self.load_frame(frame_file) for frame_file in clip_files if self.load_frame(frame_file) is not None]\n",
    "            if len(clip) == self.frames_per_clip:\n",
    "                batch_clips.append(clip)\n",
    "\n",
    "        # Convert lists to numpy arrays\n",
    "        batch_clips = np.array(batch_clips)\n",
    "        # Convert labels to one-hot encoded form\n",
    "        batch_labels = to_categorical(batch_labels, num_classes=len(self.classes))\n",
    "\n",
    "        return batch_clips, batch_labels\n",
    "\n",
    "    def load_frame(self, frame_path):\n",
    "        \"\"\"\n",
    "        Load a frame from a given path.\n",
    "\n",
    "        Args:\n",
    "            frame_path: Path to the frame.\n",
    "\n",
    "        Returns:\n",
    "            frame: Numpy array of the frame.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            frame = cv2.imread(frame_path)\n",
    "            if frame is None:\n",
    "                raise ValueError(f\"Frame is None: {frame_path}\")\n",
    "            frame = cv2.resize(frame, self.target_size)\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = frame / 255.0  # Normalize\n",
    "            return frame\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading frame: {frame_path}. Error: {e}\")\n",
    "            return None\n",
    "\n",
    "# Define the parameters\n",
    "target_size = (112, 112)  # Resize frames to this size\n",
    "batch_size = 8\n",
    "frames_per_clip = 15  # Set frames per clip to 15\n",
    "\n",
    "# Create the data generators for training, validation, and testing sets\n",
    "train_generator = VideoDataGenerator('training/', target_size, batch_size, frames_per_clip)\n",
    "val_generator = VideoDataGenerator('validation/', target_size, batch_size, frames_per_clip)\n",
    "test_generator = VideoDataGenerator('testing/', target_size, batch_size, frames_per_clip)\n",
    "\n",
    "# Build the 3D CNN model\n",
    "def build_3d_cnn(input_shape, num_classes):\n",
    "    model = Sequential([\n",
    "        Conv3D(32, kernel_size=(3, 3, 3), activation='relu', input_shape=input_shape, padding='same'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        Conv3D(64, kernel_size=(3, 3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        Conv3D(128, kernel_size=(3, 3, 3), activation='relu', padding='same'),\n",
    "        MaxPooling3D(pool_size=(2, 2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "input_shape = (frames_per_clip, target_size[0], target_size[1], 3)\n",
    "num_classes = len(train_generator.classes)\n",
    "model = build_3d_cnn(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint('3dcnnmodel_epoch_{epoch:02d}.h5', save_freq='epoch', monitor='val_loss', save_best_only=False, mode='auto')\n",
    "csv_logger = CSVLogger('training_log.csv', append=False)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=3, min_lr=0.0001)\n",
    "\n",
    "# Train the model\n",
    "try:\n",
    "    history = model.fit(train_generator, validation_data=val_generator, epochs=10, callbacks=[checkpoint, csv_logger, reduce_lr])\n",
    "except Exception as e:\n",
    "    print(f\"Error during training: {e}\")\n",
    "\n",
    "# Evaluate the model\n",
    "try:\n",
    "    test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "    print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
    "except Exception as e:\n",
    "    print(f\"Error during evaluation: {e}\")\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Predicted Class: before\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess the video\n",
    "def preprocess_video(video_path, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess the video to extract frames and prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the video is too short, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify a video\n",
    "def classify_video(model, video_path, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify a video using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the video.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_video(video_path, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    \n",
    "    # Convert index to class label\n",
    "    classes = list(class_indices.keys())\n",
    "    predicted_class = classes[predicted_index]\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"before.mp4\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the video\n",
    "    predicted_class = classify_video(model, video_path, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 948ms/step\n",
      "Predicted Class: drink\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess the video\n",
    "def preprocess_video(video_path, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess the video to extract frames and prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the video is too short, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify a video\n",
    "def classify_video(model, video_path, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify a video using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the video.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_video(video_path, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    \n",
    "    # Convert index to class label\n",
    "    classes = list(class_indices.keys())\n",
    "    predicted_class = classes[predicted_index]\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"drink.mp4\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the video\n",
    "    predicted_class = classify_video(model, video_path, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 545ms/step\n",
      "Predicted Class: friend\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess the video\n",
    "def preprocess_video(video_path, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess the video to extract frames and prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the video is too short, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify a video\n",
    "def classify_video(model, video_path, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify a video using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the video.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_video(video_path, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    \n",
    "    # Convert index to class label\n",
    "    classes = list(class_indices.keys())\n",
    "    predicted_class = classes[predicted_index]\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"computer.mp4\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the video\n",
    "    predicted_class = classify_video(model, video_path, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 555ms/step\n",
      "Predicted Class: book\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess the video\n",
    "def preprocess_video(video_path, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess the video to extract frames and prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the video is too short, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify a video\n",
    "def classify_video(model, video_path, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify a video using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the video.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_video(video_path, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    \n",
    "    # Convert index to class label\n",
    "    classes = list(class_indices.keys())\n",
    "    predicted_class = classes[predicted_index]\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"write.mp4\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the video\n",
    "    predicted_class = classify_video(model, video_path, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204447AA830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 630ms/step\n",
      "Predicted Class: sleep\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess the video\n",
    "def preprocess_video(video_path, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess the video to extract frames and prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the video is too short, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify a video\n",
    "def classify_video(model, video_path, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify a video using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the video.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_video(video_path, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    \n",
    "    # Convert index to class label\n",
    "    classes = list(class_indices.keys())\n",
    "    predicted_class = classes[predicted_index]\n",
    "    \n",
    "    return predicted_class\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"sleep.mp4\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the video\n",
    "    predicted_class = classify_video(model, video_path, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000204447AA950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 913ms/step\n",
      "Predicted Class: book\n",
      "before: 0.00%\n",
      "book: 77.15%\n",
      "call: 0.05%\n",
      "chair: 5.87%\n",
      "computer: 0.00%\n",
      "doctor: 3.05%\n",
      "drink: 0.00%\n",
      "eat: 0.04%\n",
      "family: 0.05%\n",
      "food: 0.01%\n",
      "friend: 5.22%\n",
      "go: 0.00%\n",
      "help: 1.56%\n",
      "home: 0.00%\n",
      "money: 0.11%\n",
      "read: 0.28%\n",
      "sleep: 0.00%\n",
      "work: 1.81%\n",
      "write: 4.79%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess the video\n",
    "def preprocess_video(video_path, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess the video to extract frames and prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the video is too short, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify a video\n",
    "def classify_video(model, video_path, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify a video using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the video.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_video(video_path, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"write.mp4\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the video\n",
    "    predicted_class, class_probabilities = classify_video(model, video_path, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 779ms/step\n",
      "Predicted Class: sleep\n",
      "before: 0.05%\n",
      "book: 0.00%\n",
      "call: 0.00%\n",
      "chair: 0.00%\n",
      "computer: 0.00%\n",
      "doctor: 0.00%\n",
      "drink: 6.52%\n",
      "eat: 0.02%\n",
      "family: 0.00%\n",
      "food: 0.00%\n",
      "friend: 0.00%\n",
      "go: 0.00%\n",
      "help: 0.00%\n",
      "home: 0.00%\n",
      "money: 0.00%\n",
      "read: 0.00%\n",
      "sleep: 93.41%\n",
      "work: 0.00%\n",
      "write: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess the video\n",
    "def preprocess_video(video_path, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess the video to extract frames and prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the video is too short, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify a video\n",
    "def classify_video(model, video_path, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify a video using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the video.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_video(video_path, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"sleep.mp4\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the video\n",
    "    predicted_class, class_probabilities = classify_video(model, video_path, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 495ms/step\n",
      "Predicted Class: drink\n",
      "before: 0.23%\n",
      "book: 0.20%\n",
      "call: 1.29%\n",
      "chair: 0.06%\n",
      "computer: 0.14%\n",
      "doctor: 0.02%\n",
      "drink: 35.81%\n",
      "eat: 34.62%\n",
      "family: 0.20%\n",
      "food: 25.04%\n",
      "friend: 0.55%\n",
      "go: 0.15%\n",
      "help: 0.22%\n",
      "home: 0.05%\n",
      "money: 0.00%\n",
      "read: 0.00%\n",
      "sleep: 0.04%\n",
      "work: 1.18%\n",
      "write: 0.20%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess the video\n",
    "def preprocess_video(video_path, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess the video to extract frames and prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the video is too short, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify a video\n",
    "def classify_video(model, video_path, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify a video using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the video.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_video(video_path, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"drink.mp4\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the video\n",
    "    predicted_class, class_probabilities = classify_video(model, video_path, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 688ms/step\n",
      "Predicted Class: friend\n",
      "before: 2.13%\n",
      "book: 8.25%\n",
      "call: 4.47%\n",
      "chair: 2.66%\n",
      "computer: 0.91%\n",
      "doctor: 1.85%\n",
      "drink: 3.43%\n",
      "eat: 13.54%\n",
      "family: 3.27%\n",
      "food: 12.18%\n",
      "friend: 33.13%\n",
      "go: 0.96%\n",
      "help: 2.38%\n",
      "home: 4.43%\n",
      "money: 0.45%\n",
      "read: 0.96%\n",
      "sleep: 0.34%\n",
      "work: 3.49%\n",
      "write: 1.18%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess the video\n",
    "def preprocess_video(video_path, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess the video to extract frames and prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the video is too short, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify a video\n",
    "def classify_video(model, video_path, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify a video using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the video.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_video(video_path, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"computer.mp4\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the video\n",
    "    predicted_class, class_probabilities = classify_video(model, video_path, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 798ms/step\n",
      "Predicted Class: before\n",
      "before: 34.12%\n",
      "book: 0.17%\n",
      "call: 0.53%\n",
      "chair: 1.12%\n",
      "computer: 0.53%\n",
      "doctor: 1.97%\n",
      "drink: 11.46%\n",
      "eat: 24.19%\n",
      "family: 2.30%\n",
      "food: 2.59%\n",
      "friend: 0.06%\n",
      "go: 0.62%\n",
      "help: 1.53%\n",
      "home: 1.92%\n",
      "money: 5.30%\n",
      "read: 0.73%\n",
      "sleep: 1.13%\n",
      "work: 7.17%\n",
      "write: 2.55%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess the video\n",
    "def preprocess_video(video_path, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess the video to extract frames and prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the video is too short, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify a video\n",
    "def classify_video(model, video_path, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify a video using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the video.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_video(video_path, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"before.mp4\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the video\n",
    "    predicted_class, class_probabilities = classify_video(model, video_path, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing on the test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying frames in directory: testing/before/05731\n",
      "1/1 [==============================] - 0s 451ms/step\n",
      "Predicted Class: before\n",
      "before: 100.00%\n",
      "book: 0.00%\n",
      "call: 0.00%\n",
      "chair: 0.00%\n",
      "computer: 0.00%\n",
      "doctor: 0.00%\n",
      "drink: 0.00%\n",
      "eat: 0.00%\n",
      "family: 0.00%\n",
      "food: 0.00%\n",
      "friend: 0.00%\n",
      "go: 0.00%\n",
      "help: 0.00%\n",
      "home: 0.00%\n",
      "money: 0.00%\n",
      "read: 0.00%\n",
      "sleep: 0.00%\n",
      "work: 0.00%\n",
      "write: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to load and preprocess frames from a directory\n",
    "def preprocess_frames(frame_dir, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess frames from a directory to prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    frame_files = sorted(os.listdir(frame_dir))\n",
    "    frames = []\n",
    "\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(frame_dir, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the directory has too few frames, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify frames in a directory\n",
    "def classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify frames from a directory using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the frames.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_frames(frame_dir, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    frame_dir = \"testing/before/05731\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the frames in the specified directory\n",
    "    print(f\"Classifying frames in directory: {frame_dir}\")\n",
    "    predicted_class, class_probabilities = classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying frames in directory: testing/friend/23572\n",
      "1/1 [==============================] - 1s 597ms/step\n",
      "Predicted Class: friend\n",
      "before: 0.00%\n",
      "book: 0.00%\n",
      "call: 0.00%\n",
      "chair: 0.00%\n",
      "computer: 0.00%\n",
      "doctor: 0.00%\n",
      "drink: 0.00%\n",
      "eat: 0.00%\n",
      "family: 0.00%\n",
      "food: 0.00%\n",
      "friend: 100.00%\n",
      "go: 0.00%\n",
      "help: 0.00%\n",
      "home: 0.00%\n",
      "money: 0.00%\n",
      "read: 0.00%\n",
      "sleep: 0.00%\n",
      "work: 0.00%\n",
      "write: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to load and preprocess frames from a directory\n",
    "def preprocess_frames(frame_dir, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess frames from a directory to prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    frame_files = sorted(os.listdir(frame_dir))\n",
    "    frames = []\n",
    "\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(frame_dir, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the directory has too few frames, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify frames in a directory\n",
    "def classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify frames from a directory using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the frames.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_frames(frame_dir, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    frame_dir = \"testing/friend/23572\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the frames in the specified directory\n",
    "    print(f\"Classifying frames in directory: {frame_dir}\")\n",
    "    predicted_class, class_probabilities = classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying frames in directory: testing/read/46268 - Copy\n",
      "1/1 [==============================] - 1s 624ms/step\n",
      "Predicted Class: read\n",
      "before: 0.00%\n",
      "book: 0.00%\n",
      "call: 0.00%\n",
      "chair: 0.00%\n",
      "computer: 0.00%\n",
      "doctor: 0.00%\n",
      "drink: 0.00%\n",
      "eat: 0.00%\n",
      "family: 0.00%\n",
      "food: 0.00%\n",
      "friend: 0.00%\n",
      "go: 0.00%\n",
      "help: 0.00%\n",
      "home: 0.00%\n",
      "money: 0.00%\n",
      "read: 100.00%\n",
      "sleep: 0.00%\n",
      "work: 0.00%\n",
      "write: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to load and preprocess frames from a directory\n",
    "def preprocess_frames(frame_dir, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess frames from a directory to prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    frame_files = sorted(os.listdir(frame_dir))\n",
    "    frames = []\n",
    "\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(frame_dir, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the directory has too few frames, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify frames in a directory\n",
    "def classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify frames from a directory using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the frames.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_frames(frame_dir, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    frame_dir = \"testing/read/46268 - Copy\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the frames in the specified directory\n",
    "    print(f\"Classifying frames in directory: {frame_dir}\")\n",
    "    predicted_class, class_probabilities = classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying frames in directory: testing/family/69316 - Copy\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "Predicted Class: food\n",
      "before: 0.01%\n",
      "book: 0.00%\n",
      "call: 0.00%\n",
      "chair: 0.02%\n",
      "computer: 0.02%\n",
      "doctor: 0.01%\n",
      "drink: 0.00%\n",
      "eat: 0.01%\n",
      "family: 34.86%\n",
      "food: 64.97%\n",
      "friend: 0.01%\n",
      "go: 0.04%\n",
      "help: 0.00%\n",
      "home: 0.00%\n",
      "money: 0.00%\n",
      "read: 0.00%\n",
      "sleep: 0.00%\n",
      "work: 0.00%\n",
      "write: 0.04%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to load and preprocess frames from a directory\n",
    "def preprocess_frames(frame_dir, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess frames from a directory to prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    frame_files = sorted(os.listdir(frame_dir))\n",
    "    frames = []\n",
    "\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(frame_dir, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the directory has too few frames, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify frames in a directory\n",
    "def classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify frames from a directory using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the frames.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_frames(frame_dir, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    frame_dir = \"testing/family/69316 - Copy\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the frames in the specified directory\n",
    "    print(f\"Classifying frames in directory: {frame_dir}\")\n",
    "    predicted_class, class_probabilities = classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying frames in directory: testing/friend/23572\n",
      "1/1 [==============================] - 1s 512ms/step\n",
      "Predicted Class: friend\n",
      "before: 0.00%\n",
      "book: 0.00%\n",
      "call: 0.00%\n",
      "chair: 0.00%\n",
      "computer: 0.00%\n",
      "doctor: 0.00%\n",
      "drink: 0.00%\n",
      "eat: 0.00%\n",
      "family: 0.00%\n",
      "food: 0.00%\n",
      "friend: 100.00%\n",
      "go: 0.00%\n",
      "help: 0.00%\n",
      "home: 0.00%\n",
      "money: 0.00%\n",
      "read: 0.00%\n",
      "sleep: 0.00%\n",
      "work: 0.00%\n",
      "write: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to load and preprocess frames from a directory\n",
    "def preprocess_frames(frame_dir, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess frames from a directory to prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    frame_files = sorted(os.listdir(frame_dir))\n",
    "    frames = []\n",
    "\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(frame_dir, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the directory has too few frames, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify frames in a directory\n",
    "def classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify frames from a directory using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the frames.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_frames(frame_dir, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    frame_dir = \"testing/friend/23572\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the frames in the specified directory\n",
    "    print(f\"Classifying frames in directory: {frame_dir}\")\n",
    "    predicted_class, class_probabilities = classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying frames in directory: testing/go/24961\n",
      "1/1 [==============================] - 1s 528ms/step\n",
      "Predicted Class: go\n",
      "before: 0.00%\n",
      "book: 0.00%\n",
      "call: 0.00%\n",
      "chair: 0.00%\n",
      "computer: 0.00%\n",
      "doctor: 0.00%\n",
      "drink: 0.16%\n",
      "eat: 0.00%\n",
      "family: 0.00%\n",
      "food: 0.00%\n",
      "friend: 0.00%\n",
      "go: 99.83%\n",
      "help: 0.00%\n",
      "home: 0.00%\n",
      "money: 0.00%\n",
      "read: 0.00%\n",
      "sleep: 0.00%\n",
      "work: 0.00%\n",
      "write: 0.00%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to load and preprocess frames from a directory\n",
    "def preprocess_frames(frame_dir, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess frames from a directory to prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    frame_files = sorted(os.listdir(frame_dir))\n",
    "    frames = []\n",
    "\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(frame_dir, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the directory has too few frames, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify frames in a directory\n",
    "def classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify frames from a directory using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the frames.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_frames(frame_dir, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    frame_dir = \"testing/go/24961\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the frames in the specified directory\n",
    "    print(f\"Classifying frames in directory: {frame_dir}\")\n",
    "    predicted_class, class_probabilities = classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 74\u001b[0m\n\u001b[0;32m     72\u001b[0m target_size \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m112\u001b[39m, \u001b[38;5;241m112\u001b[39m)\n\u001b[0;32m     73\u001b[0m frames_per_clip \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m15\u001b[39m\n\u001b[1;32m---> 74\u001b[0m class_indices \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_generator\u001b[49m\u001b[38;5;241m.\u001b[39mclass_indices  \u001b[38;5;66;03m# Assuming the same class_indices used during training\u001b[39;00m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m# Load the trained model\u001b[39;00m\n\u001b[0;32m     77\u001b[0m model \u001b[38;5;241m=\u001b[39m load_model(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m3dcnnmodel_epoch_07.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to load and preprocess frames from a directory\n",
    "def preprocess_frames(frame_dir, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess frames from a directory to prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    frame_files = sorted(os.listdir(frame_dir))\n",
    "    frames = []\n",
    "\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(frame_dir, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the directory has too few frames, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify frames in a directory\n",
    "def classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify frames from a directory using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the frames.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_frames(frame_dir, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    frame_dir = \"testing/money/36654\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = train_generator.class_indices  # Assuming the same class_indices used during training\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the frames in the specified directory\n",
    "    print(f\"Classifying frames in directory: {video_frames}\")\n",
    "    predicted_class, class_probabilities = classify_frames(model, video_frames, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "video - testing Again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying frames from video: before.mp4\n",
      "1/1 [==============================] - 0s 308ms/step\n",
      "Predicted Class: before\n",
      "before: 34.12%\n",
      "book: 0.17%\n",
      "call: 0.53%\n",
      "chair: 1.12%\n",
      "computer: 0.53%\n",
      "doctor: 1.97%\n",
      "drink: 11.46%\n",
      "eat: 24.19%\n",
      "family: 2.30%\n",
      "food: 2.59%\n",
      "friend: 0.06%\n",
      "go: 0.62%\n",
      "help: 1.53%\n",
      "home: 1.92%\n",
      "money: 5.30%\n",
      "read: 0.73%\n",
      "sleep: 1.13%\n",
      "work: 7.17%\n",
      "write: 2.55%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to preprocess frames from a video\n",
    "def preprocess_video(video_path, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess frames from a video to prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the video is too short, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify frames in a video\n",
    "def classify_video(model, video_path, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify frames from a video using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        video_path: Path to the video file.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the frames.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_video(video_path, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"before.mp4\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = {\n",
    "        \"before\": 0,\n",
    "        \"book\": 1,\n",
    "        \"call\": 2,\n",
    "        \"chair\": 3,\n",
    "        \"computer\": 4,\n",
    "        \"doctor\": 5,\n",
    "        \"drink\": 6,\n",
    "        \"eat\": 7,\n",
    "        \"family\": 8,\n",
    "        \"food\": 9,\n",
    "        \"friend\": 10,\n",
    "        \"go\": 11,\n",
    "        \"help\": 12,\n",
    "        \"home\": 13,\n",
    "        \"money\": 14,\n",
    "        \"read\": 15,\n",
    "        \"sleep\": 16,\n",
    "        \"work\": 17,\n",
    "        \"write\": 18\n",
    "    }\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Classify the frames in the specified video\n",
    "    print(f\"Classifying frames from video: {video_path}\")\n",
    "    predicted_class, class_probabilities = classify_video(model, video_path, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifying frames in directory: video_frames\n",
      "1/1 [==============================] - 0s 452ms/step\n",
      "Predicted Class: eat\n",
      "before: 0.20%\n",
      "book: 0.16%\n",
      "call: 1.09%\n",
      "chair: 0.05%\n",
      "computer: 0.13%\n",
      "doctor: 0.01%\n",
      "drink: 35.12%\n",
      "eat: 35.75%\n",
      "family: 0.19%\n",
      "food: 25.25%\n",
      "friend: 0.43%\n",
      "go: 0.13%\n",
      "help: 0.20%\n",
      "home: 0.04%\n",
      "money: 0.00%\n",
      "read: 0.00%\n",
      "sleep: 0.04%\n",
      "work: 1.04%\n",
      "write: 0.17%\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Function to save video frames to a directory\n",
    "def save_video_frames(video_path, frame_dir, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Save video frames to a directory.\n",
    "\n",
    "    Args:\n",
    "        video_path: Path to the video file.\n",
    "        frame_dir: Path to the directory to save frames.\n",
    "        frames_per_clip: Number of frames to extract per clip.\n",
    "    \"\"\"\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    \n",
    "    if not os.path.exists(frame_dir):\n",
    "        os.makedirs(frame_dir)\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame_path = os.path.join(frame_dir, f\"frame_{frame_count:04d}.jpg\")\n",
    "        cv2.imwrite(frame_path, frame)\n",
    "        frame_count += 1\n",
    "        if frame_count == frames_per_clip:\n",
    "            break\n",
    "    \n",
    "    cap.release()\n",
    "\n",
    "# Function to preprocess frames from a directory\n",
    "def preprocess_frames(frame_dir, target_size, frames_per_clip):\n",
    "    \"\"\"\n",
    "    Preprocess frames from a directory to prepare them for the model.\n",
    "\n",
    "    Args:\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "\n",
    "    Returns:\n",
    "        processed_clip: Numpy array of the processed video clip.\n",
    "    \"\"\"\n",
    "    frame_files = sorted(os.listdir(frame_dir))\n",
    "    frames = []\n",
    "\n",
    "    for frame_file in frame_files:\n",
    "        frame_path = os.path.join(frame_dir, frame_file)\n",
    "        frame = cv2.imread(frame_path)\n",
    "        frame = cv2.resize(frame, target_size)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        frame = frame / 255.0  # Normalize\n",
    "        frames.append(frame)\n",
    "\n",
    "    # Select the first `frames_per_clip` frames\n",
    "    if len(frames) >= frames_per_clip:\n",
    "        processed_clip = np.array(frames[:frames_per_clip])\n",
    "    else:\n",
    "        # If the directory has too few frames, repeat frames to fit the required length\n",
    "        processed_clip = np.array(frames * (frames_per_clip // len(frames) + 1))[:frames_per_clip]\n",
    "\n",
    "    return processed_clip\n",
    "\n",
    "# Function to classify frames in a directory\n",
    "def classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices):\n",
    "    \"\"\"\n",
    "    Classify frames from a directory using the trained model.\n",
    "\n",
    "    Args:\n",
    "        model: Trained 3D CNN model.\n",
    "        frame_dir: Path to the directory containing the frames.\n",
    "        target_size: Tuple (height, width) for resizing frames.\n",
    "        frames_per_clip: Number of frames in each video clip.\n",
    "        class_indices: Dictionary mapping class names to indices.\n",
    "\n",
    "    Returns:\n",
    "        predicted_class: The predicted class label for the frames.\n",
    "        class_probabilities: Dictionary with class labels and their corresponding probabilities.\n",
    "    \"\"\"\n",
    "    processed_clip = preprocess_frames(frame_dir, target_size, frames_per_clip)\n",
    "    processed_clip = np.expand_dims(processed_clip, axis=0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    predictions = model.predict(processed_clip)\n",
    "    predicted_index = np.argmax(predictions)\n",
    "    predicted_class = list(class_indices.keys())[predicted_index]\n",
    "    \n",
    "    # Get probabilities for each class\n",
    "    class_probabilities = {class_name: prob for class_name, prob in zip(class_indices.keys(), predictions[0])}\n",
    "    \n",
    "    return predicted_class, class_probabilities\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    video_path = \"drink.mp4\"\n",
    "    frame_dir = \"video_frames\"\n",
    "    target_size = (112, 112)\n",
    "    frames_per_clip = 15\n",
    "    class_indices = {\n",
    "        \"before\": 0,\n",
    "        \"book\": 1,\n",
    "        \"call\": 2,\n",
    "        \"chair\": 3,\n",
    "        \"computer\": 4,\n",
    "        \"doctor\": 5,\n",
    "        \"drink\": 6,\n",
    "        \"eat\": 7,\n",
    "        \"family\": 8,\n",
    "        \"food\": 9,\n",
    "        \"friend\": 10,\n",
    "        \"go\": 11,\n",
    "        \"help\": 12,\n",
    "        \"home\": 13,\n",
    "        \"money\": 14,\n",
    "        \"read\": 15,\n",
    "        \"sleep\": 16,\n",
    "        \"work\": 17,\n",
    "        \"write\": 18\n",
    "    }\n",
    "\n",
    "    # Load the trained model\n",
    "    model = load_model('3dcnnmodel_epoch_07.h5')\n",
    "\n",
    "    # Save video frames to a directory\n",
    "    save_video_frames(video_path, frame_dir, frames_per_clip)\n",
    "\n",
    "    # Classify the frames in the specified directory\n",
    "    print(f\"Classifying frames in directory: {frame_dir}\")\n",
    "    predicted_class, class_probabilities = classify_frames(model, frame_dir, target_size, frames_per_clip, class_indices)\n",
    "    print(f\"Predicted Class: {predicted_class}\")\n",
    "\n",
    "    # Print the probabilities for each class\n",
    "    for class_name, prob in class_probabilities.items():\n",
    "        print(f\"{class_name}: {prob * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "office "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
